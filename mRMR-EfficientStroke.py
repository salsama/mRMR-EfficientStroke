# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CVWYygfQkTR6I6tMoGuuSXl8ij9c2sW-
"""

from google.colab import files
uploaded = files.upload()
# Note:  The provided file path is not compatible with the files.upload() function.
# It expects a filename or a list of filenames.  To upload a local file, you would
# typically use files.upload() and then access the uploaded files using the returned dictionary.
# Example: uploaded_file = list(uploaded.keys())[0]

import zipfile
import os

zip_path = "----_2.v1i.multiclass.zip"  # استبدل باسم الملف الذي رفعته
extract_path = "images_dataset"  # مجلد حفظ الصور بعد فك الضغط

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("تم فك الضغط بنجاح!")

import matplotlib.pyplot as plt
import os
import cv2
from glob import glob

# عرض أول 5 صور من المجلد بعد فك الضغط
image_paths = glob(os.path.join(extract_path, '*'))

fig, axes = plt.subplots(1, 5, figsize=(15, 5))
for i, img_path in enumerate(image_paths[:5]):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # تحويل ألوان OpenCV إلى RGB
    axes[i].imshow(img)
    axes[i].axis("off")
plt.show()

import matplotlib.pyplot as plt
import os
import cv2
from glob import glob

# عرض أول 5 صور من المجلد بعد فك الضغط
image_paths = glob(os.path.join(extract_path, '*'))

fig, axes = plt.subplots(1, 5, figsize=(15, 5))
for i, img_path in enumerate(image_paths[:5]):
    img = cv2.imread(img_path)

    # Check if image was loaded successfully
    if img is not None:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # تحويل ألوان OpenCV إلى RGB
        axes[i].imshow(img)
        axes[i].axis("off")
    else:
        print(f"Failed to load image: {img_path}")

plt.show()

import matplotlib.pyplot as plt
import os
import cv2
from glob import glob

# تحديد الامتدادات الخاصة بالصور فقط
image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")

# جمع جميع الملفات التي تنتهي بامتداد صورة فقط
image_paths = [f for f in glob(os.path.join(extract_path, '*')) if f.lower().endswith(image_extensions)]

# التأكد من وجود صور
if len(image_paths) == 0:
    print("لم يتم العثور على أي صور في المجلد المحدد.")
else:
    fig, axes = plt.subplots(1, min(5, len(image_paths)), figsize=(15, 5))  # عرض 5 صور فقط أو أقل حسب المتوفر

    for i, img_path in enumerate(image_paths[:5]):
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # تحويل OpenCV إلى RGB
            axes[i].imshow(img)
            axes[i].axis("off")
        else:
            print(f"فشل تحميل الصورة: {img_path}")

    plt.show()

import os

extract_path = "images_dataset"  # المجلد الذي تم فك ضغط الصور فيه
files = os.listdir(extract_path)  # جلب جميع الملفات والمجلدات داخله

print("محتوى المجلد بعد فك الضغط:")
for file in files:
    print(file)

import os
from glob import glob

# المسار الرئيسي حيث تم فك الضغط
extract_path = "images_dataset"

# البحث عن الصور داخل المجلدات الفرعية (train, test, valid)
image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")

# جمع جميع مسارات الصور داخل المجلدات الفرعية
image_paths = []
for folder in ["train", "valid", "test"]:  # البحث فقط داخل هذه المجلدات
    folder_path = os.path.join(extract_path, folder)
    image_paths.extend(glob(os.path.join(folder_path, "**/*"), recursive=True))  # البحث العميق داخل كل المجلدات

# تصفية الصور فقط
image_paths = [f for f in image_paths if f.lower().endswith(image_extensions)]

print(f"✅ تم العثور على {len(image_paths)} صورة داخل المجلدات الفرعية.")

import matplotlib.pyplot as plt
import cv2

if len(image_paths) > 0:
    fig, axes = plt.subplots(1, min(5, len(image_paths)), figsize=(15, 5))  # عرض حتى 5 صور فقط
    for i, img_path in enumerate(image_paths[:5]):
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            axes[i].imshow(img)
            axes[i].axis("off")
        else:
            print(f"⚠️ فشل تحميل الصورة: {img_path}")
    plt.show()
else:
    print("❌ لم يتم العثور على أي صور داخل المجلدات الفرعية.")

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
from tensorflow.keras.applications import MobileNetV2, ResNet50
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.preprocessing import image

# اختر النموذج
use_mobilenet = True  # True لاستخدام MobileNetV2, False لاستخدام ResNet50

if use_mobilenet:
    model = MobileNetV2(weights="imagenet")
    preprocess_input = mobilenet_preprocess
    model_name = "MobileNetV2"
else:
    model = ResNet50(weights="imagenet")
    preprocess_input = resnet_preprocess
    model_name = "ResNet50"

print(f"✅ تم تحميل نموذج {model_name}")

def predict_image(img_path, model, preprocess_input):
    """ دالة لتحليل الصورة باستخدام النموذج المختار """
    img = image.load_img(img_path, target_size=(224, 224))  # ضبط حجم الصورة ليتناسب مع النموذج
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    preds = model.predict(img_array)
    decoded_preds = tf.keras.applications.imagenet_utils.decode_predictions(preds, top=3)[0]

    return decoded_preds

# تجربة على صورة واحدة من البيانات
sample_img = image_paths[0]
predictions = predict_image(sample_img, model, preprocess_input)

# عرض الصورة مع التوقعات
img = cv2.imread(sample_img)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.imshow(img)
plt.axis("off")
plt.title(f"📌 {predictions[0][1]} ({predictions[0][2]*100:.2f}%)")
plt.show()

# طباعة أعلى 3 توقعات
for pred in predictions:
    print(f"{pred[1]}: {pred[2]*100:.2f}%")

num_images = 5  # عدد الصور التي نريد تصنيفها
fig, axes = plt.subplots(1, num_images, figsize=(15, 5))

for i, img_path in enumerate(image_paths[:num_images]):
    predictions = predict_image(img_path, model, preprocess_input)
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    axes[i].imshow(img)
    axes[i].axis("off")
    axes[i].set_title(f"{predictions[0][1]} ({predictions[0][2]*100:.2f}%)")

plt.show()

import pandas as pd

results = []

for img_path in image_paths:
    predictions = predict_image(img_path, model, preprocess_input)
    results.append({
        "Image": img_path,
        "Prediction_1": predictions[0][1],
        "Confidence_1": predictions[0][2] * 100,
        "Prediction_2": predictions[1][1],
        "Confidence_2": predictions[1][2] * 100,
        "Prediction_3": predictions[2][1],
        "Confidence_3": predictions[2][2] * 100,
    })

df = pd.DataFrame(results)
df.to_csv("image_classification_results.csv", index=False)

print("✅ تم حفظ النتائج في ملف image_classification_results.csv")



import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0, ResNet50
from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# مسار البيانات
data_dir = "images_dataset"

# تحميل الصور مع التهيئة المسبقة للنموذج
img_size = (224, 224)  # حجم الصور المناسب للنموذج
batch_size = 32

train_datagen = ImageDataGenerator(
    preprocessing_function=efficientnet_preprocess,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% من البيانات للاختبار
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

class_names = list(train_generator.class_indices.keys())
print(f"✅ Detected Classes: {class_names}")

import os

data_dir = "images_dataset"

# عرض المجلدات داخل `images_dataset`
if os.path.exists(data_dir):
    print("✅ Main directory exists:", os.listdir(data_dir))
    if os.path.exists(os.path.join(data_dir, "train")):
        print("✅ Train directory exists:", os.listdir(os.path.join(data_dir, "train")))
    else:
        print("❌ Train directory is missing!")
else:
    print("❌ Main directory is missing!")

import os

zip_path = "/----_2.v1i.multiclass.zip"  # استبدل باسم الملف إذا كان مختلفًا

if os.path.exists(zip_path):
    print("✅ The ZIP file exists!")
else:
    print("❌ The ZIP file does NOT exist. Check the path!")

import zipfile

extract_path = "/extracted_data"  # مسار المجلد الذي سيتم استخراج الملفات إليه

# فك الضغط
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ Files extracted successfully to:", extract_path)

import zipfile

zip_path = "/content/----_2.v1i.multiclass.zip"  # تحقق من الاسم الصحيح
extract_path = "/content/extracted_data"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ Files extracted successfully to:", extract_path)

import os

# عرض الملفات في مجلد Google Colab
files = os.listdir("/content/")
print("📂 Files in /content/:", files)

# التحقق مما إذا كان الملف المطلوب موجودًا
zip_path = "/----_2.v1i.multiclass.zip"
if zip_path in files:
    print("✅ File found:", zip_path)
else:
    print("❌ File not found! Check the file name or upload it again.")

from google.colab import files

uploaded = files.upload()  # ستظهر نافذة لرفع الملف من جهازك

import os
print("📂 Files in /content/:", os.listdir("/content/"))

import zipfile

zip_path = "/content/----_2.v1i.multiclass.zip"  # استخدم الاسم الصحيح من قائمة الملفات
extract_path = "/content/extracted_data"

# فك الضغط
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ Files extracted successfully to:", extract_path)

import os

# عرض الملفات داخل المجلد المستخرج
print("📂 Extracted files:", os.listdir(extract_path))

dataset_path = "/content/extracted_data/images_dataset"

if os.path.exists(dataset_path):
    print("✅ Dataset is ready at:", dataset_path)
    print("📂 Folders inside:", os.listdir(dataset_path))
else:
    print("❌ Dataset folder not found! Check extraction path.")

import os

extract_path = "/content/extracted_data"

# عرض الملفات داخل المجلد المستخرج
print("📂 Extracted files and folders:", os.listdir(extract_path))



data_dir = "/content/extracted_data"

import os

print("📂 Available datasets:", os.listdir(data_dir))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# إعداد التحويلات للصورة
img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,  # إعادة قياس القيم بين 0 و 1
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

# عرض الفئات المكتشفة
class_names = list(train_generator.class_indices.keys())
print(f"✅ Detected Classes: {class_names}")

print("📂 Classes inside 'train':", os.listdir(os.path.join(data_dir, "train")))

📂 Classes inside 'train': ['artery', 'vein']

import os

data_dir = "/content/extracted_data"
train_path = os.path.join(data_dir, "train")

print("Classes inside 'train':", os.listdir(train_path))

import tensorflow as tf
import numpy as np
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0, ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# المسار الرئيسي للبيانات
data_dir = "/content/extracted_data"

# حجم الصورة المطلوب للنموذج
img_size = (224, 224)
batch_size = 32

# تجهيز بيانات التدريب والتقييم مع التحسينات
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% من البيانات ستكون للتقييم
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

# طباعة الفئات المكتشفة
class_names = list(train_generator.class_indices.keys())
print(f"✅ Detected Classes: {class_names}")

use_efficientnet = True  # اختر True لاستخدام EfficientNetB0 أو False لاستخدام ResNet50

if use_efficientnet:
    base_model = EfficientNetB0(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
    preprocess_input = tf.keras.applications.efficientnet.preprocess_input
    model_name = "EfficientNetB0"
else:
    base_model = ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
    preprocess_input = tf.keras.applications.resnet50.preprocess_input
    model_name = "ResNet50"

# تجميد الطبقات الأساسية
base_model.trainable = False

# إضافة الطبقات الجديدة
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation="relu")(x)
x = Dropout(0.4)(x)  # تجنب فرط التكيف (Overfitting)
output_layer = Dense(len(class_names), activation="softmax")(x)  # عدد الفئات بناءً على بياناتك

# بناء النموذج النهائي
model = Model(inputs=base_model.input, outputs=output_layer)

# تجميع النموذج
model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# عرض ملخص النموذج
model.summary()
print(f"✅ Model {model_name} is ready!")

import pandas as pd

# استخراج الملخص كنص
model_summary = []
model.summary(print_fn=lambda x: model_summary.append(x))

# تحويل البيانات إلى جدول وحفظها
df_summary = pd.DataFrame({"Model Summary": model_summary})
df_summary.to_csv("model_summary.csv", index=False)

print("✅ Model summary saved as 'model_summary.csv'")

from google.colab import files

# تحميل الملف إلى جهازك
files.download("model_summary.csv")

import pandas as pd

# استخراج الملخص كنص
model_summary = []
model.summary(print_fn=lambda x: model_summary.append(x))

# حفظه في ملف نصي منسق بشكل أوضح
summary_file_path = "model_summary.txt"

with open(summary_file_path, "w") as f:
    for line in model_summary:
        f.write(line + "\n")

print(f"✅ Model summary saved as '{summary_file_path}'")

from google.colab import files
files.download("model_summary.txt")

# عدد الدورات التدريبية
epochs = 10

# تدريب النموذج
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=epochs,
    verbose=1
)

# حفظ النموذج المدرب
model.save("artery_vein_classifier.h5")
print("✅ Model Saved Successfully!")

import os

train_path = "/content/extracted_data/train"
valid_path = "/content/extracted_data/valid"

print("📂 Train set contents:", os.listdir(train_path))
print("📂 Validation set contents:", os.listdir(valid_path))

import os

train_path = "/content/extracted_data/train"
valid_path = "/content/extracted_data/valid"
test_path = "/content/extracted_data/test"

# إنشاء مجلدات الفئات داخل كل مجموعة بيانات
for path in [train_path, valid_path, test_path]:
    os.makedirs(os.path.join(path, "artery"), exist_ok=True)
    os.makedirs(os.path.join(path, "vein"), exist_ok=True)

print("✅ Folders 'artery' and 'vein' have been created inside train, valid, and test.")

import shutil

# دالة لتصنيف الصور تلقائيًا استنادًا إلى أسمائها
def move_images_to_folders(base_path):
    for filename in os.listdir(base_path):
        file_path = os.path.join(base_path, filename)
        if os.path.isfile(file_path):  # التأكد من أنه ملف صورة
            if "A" in filename:  # افترض أن الصور الشريانية تحتوي على "A" في الاسم
                shutil.move(file_path, os.path.join(base_path, "artery", filename))
            elif "V" in filename:  # افترض أن الصور الوريدية تحتوي على "V" في الاسم
                shutil.move(file_path, os.path.join(base_path, "vein", filename))

# نقل الصور داخل كل مجموعة بيانات
for path in [train_path, valid_path, test_path]:
    move_images_to_folders(path)

print("✅ Images have been moved to their respective folders.")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# تجهيز البيانات
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    valid_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode="categorical",
    subset="validation"
)

print("✅ Data generators are ready!")

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=10,
    verbose=1
)

print("✅ Class indices:", train_generator.class_indices)
print("✅ Number of classes detected:", len(train_generator.class_indices))

# إعادة إنشاء الطبقة الأخيرة بعدد الفئات الصحيح
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation="relu")(x)
x = Dropout(0.4)(x)  # تجنب فرط التكيف (Overfitting)
output_layer = Dense(len(train_generator.class_indices), activation="softmax")(x)  # عدد الفئات بناءً على البيانات

# إعادة بناء النموذج
model = Model(inputs=base_model.input, outputs=output_layer)

# تجميع النموذج من جديد
model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

print("✅ Model recompiled with the correct number of classes!")

train_generator.reset()
valid_generator.reset()

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=10,
    verbose=1
)

import pandas as pd

# تحويل بيانات التدريب إلى DataFrame
history_df = pd.DataFrame(history.history)

# حفظ النتائج في ملف Excel
history_df.to_excel("training_results.xlsx", index=False)

print("✅ Training results saved as 'training_results.xlsx'")

from google.colab import files
files.download("training_results.xlsx")

import matplotlib.pyplot as plt
import pandas as pd

# تحويل بيانات التدريب إلى DataFrame
history_df = pd.DataFrame(history.history)

# 📊 رسم دقة النموذج أثناء التدريب
plt.figure(figsize=(10, 5))
plt.plot(history_df['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history_df['val_accuracy'], label='Validation Accuracy', linestyle='dashed', marker='o')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('📈 Model Training Accuracy Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# 📉 رسم الخسارة (Loss) أثناء التدريب
plt.figure(figsize=(10, 5))
plt.plot(history_df['loss'], label='Training Loss', marker='o')
plt.plot(history_df['val_loss'], label='Validation Loss', linestyle='dashed', marker='o')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('📉 Model Training Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

import os
import cv2
import random
import numpy as np
import matplotlib.pyplot as plt

# تحديد المسارات
dataset_path = "/content/extracted_data/test"  # استبدل بـ `train` أو `valid` لاختبار صور مختلفة
categories = ["artery", "vein"]

# جمع جميع الصور داخل المجلدات
image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    # التأكد من عدم اختيار أكثر من عدد الصور المتاحة
    num_images_to_select = min(3, len(images))  # إذا كان هناك أقل من 3 صور، اختر العدد المتاح فقط
    selected_images = random.sample(images, num_images_to_select)

    for img in selected_images:
        image_paths.append(os.path.join(category_path, img))

print(f"✅ Selected {len(image_paths)} images for visualization")

# عرض الصور مع تحديد الشرايين والأوردة
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

for i, img_path in enumerate(image_paths):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # تحويل الألوان إلى RGB

    # استخراج اسم الفئة من المسار
    label = "Artery" if "artery" in img_path else "Vein"
    color = (255, 0, 0) if label == "Artery" else (0, 255, 0)  # أحمر للشرايين، أخضر للأوردة

    # رسم مستطيل افتراضي حول المنطقة (لتوضيح الفئة فقط)
    h, w, _ = img.shape
    start_point = (int(w * 0.2), int(h * 0.2))  # نقطة البداية للمستطيل
    end_point = (int(w * 0.8), int(h * 0.8))  # نقطة النهاية للمستطيل
    cv2.rectangle(img, start_point, end_point, color, 3)

    # إضافة نص التصنيف
    cv2.putText(img, label, (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # عرض الصورة
    row, col = i // 3, i % 3
    axes[row, col].imshow(img)
    axes[row, col].axis("off")
    axes[row, col].set_title(f"{label}")

plt.suptitle("Highlighted Arteries and Veins", fontsize=16)
plt.show()

import os

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

for category in categories:
    category_path = os.path.join(dataset_path, category)
    num_images = len(os.listdir(category_path))
    print(f"📂 {category} contains {num_images} images")

import os

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

for category in categories:
    category_path = os.path.join(dataset_path, category)
    num_images = len(os.listdir(category_path))
    print(f"📂 {category} contains {num_images} images")

import os

dataset_path = "/content/extracted_data/test"

# البحث عن جميع الصور في `test/`
all_images = []
for root, dirs, files in os.walk(dataset_path):
    for file in files:
        if file.lower().endswith((".png", ".jpg", ".jpeg")):
            all_images.append(os.path.join(root, file))

print(f"📂 Found {len(all_images)} images in 'test/'")

import shutil

train_vein_path = "/content/extracted_data/train/vein"
test_vein_path = "/content/extracted_data/test/vein"

# إنشاء مجلد `test/vein/` إذا لم يكن موجودًا
os.makedirs(test_vein_path, exist_ok=True)

# نسخ بعض الصور من `train/vein/` إلى `test/vein/`
num_images_to_copy = 10  # عدد الصور التي تريد نسخها

train_vein_images = os.listdir(train_vein_path)
num_images_to_copy = min(num_images_to_copy, len(train_vein_images))

for img in train_vein_images[:num_images_to_copy]:
    shutil.copy(os.path.join(train_vein_path, img), os.path.join(test_vein_path, img))

print(f"✅ Copied {num_images_to_copy} vein images from 'train/vein/' to 'test/vein/'")

vein_images = os.listdir("/content/extracted_data/test/vein")
print(f"✅ Now 'test/vein/' contains {len(vein_images)} images")

import os
import cv2
import random
import numpy as np
import matplotlib.pyplot as plt

# تحديد المسارات
dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

# جمع جميع الصور داخل المجلدات
image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    # التأكد من اختيار العدد المتاح فقط
    num_images_to_select = min(3, len(images))  # إذا كان هناك أقل من 3 صور، اختر العدد المتاح فقط
    selected_images = random.sample(images, num_images_to_select)

    for img in selected_images:
        image_paths.append(os.path.join(category_path, img))

# 📌 التأكد من أن لدينا صورًا لكل فئة
print(f"✅ Selected {len(image_paths)} images for visualization")

# تحديد عدد الصفوف والأعمدة لعرض الصور
num_images = len(image_paths)
rows = (num_images // 3) + (num_images % 3 > 0)  # حساب عدد الصفوف بناءً على عدد الصور
fig, axes = plt.subplots(rows, 3, figsize=(15, 10))

# جعل المحاور مصفوفة لضمان عدم حدوث خطأ إذا كان عدد الصور أقل من 6
axes = np.array(axes).reshape(-1)

# عرض الصور مع تمييز الشرايين والأوردة
for i, img_path in enumerate(image_paths):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # تحويل الألوان إلى RGB

    # استخراج اسم الفئة من المسار
    label = "Artery" if "artery" in img_path else "Vein"
    color = (255, 0, 0) if label == "Artery" else (0, 255, 0)  # أحمر للشرايين، أخضر للأوردة

    # رسم مستطيل افتراضي حول المنطقة (لتوضيح الفئة فقط)
    h, w, _ = img.shape
    start_point = (int(w * 0.2), int(h * 0.2))  # نقطة البداية للمستطيل
    end_point = (int(w * 0.8), int(h * 0.8))  # نقطة النهاية للمستطيل
    cv2.rectangle(img, start_point, end_point, color, 3)

    # إضافة نص التصنيف فوق الصورة
    cv2.putText(img, label, (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # عرض الصورة
    axes[i].imshow(img)
    axes[i].axis("off")
    axes[i].set_title(f"{label}")

# إزالة المحاور الفارغة إذا كان عدد الصور أقل من 6
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.suptitle("Highlighted Arteries and Veins", fontsize=16)
plt.show()

import os

vein_path = "/content/extracted_data/test/vein"
artery_path = "/content/extracted_data/test/artery"

num_vein_images = len(os.listdir(vein_path))
num_artery_images = len(os.listdir(artery_path))

print(f"📂 Artery images: {num_artery_images}")
print(f"📂 Vein images: {num_vein_images}")

import shutil

train_vein_path = "/content/extracted_data/train/vein"
test_vein_path = "/content/extracted_data/test/vein"

# إنشاء المجلد إذا لم يكن موجودًا
os.makedirs(test_vein_path, exist_ok=True)

# نسخ بعض الصور من `train/vein/` إلى `test/vein/`
num_images_to_copy = 10  # عدد الصور المطلوب نسخها
train_vein_images = os.listdir(train_vein_path)
num_images_to_copy = min(num_images_to_copy, len(train_vein_images))

for img in train_vein_images[:num_images_to_copy]:
    shutil.copy(os.path.join(train_vein_path, img), os.path.join(test_vein_path, img))

print(f"✅ Copied {num_images_to_copy} vein images from 'train/vein/' to 'test/vein/'")

import random

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

# التأكد من أن الصور تُختار من كل فئة
image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    if len(images) > 0:
        num_images_to_select = min(3, len(images))  # اختيار العدد المتاح فقط
        selected_images = random.sample(images, num_images_to_select)

        for img in selected_images:
            image_paths.append(os.path.join(category_path, img))

print(f"✅ Selected {len(image_paths)} images: {image_paths}")

import cv2
import numpy as np
import matplotlib.pyplot as plt

# تحديد عدد الصفوف والأعمدة لعرض الصور
num_images = len(image_paths)
rows = (num_images // 3) + (num_images % 3 > 0)  # حساب عدد الصفوف بناءً على عدد الصور
fig, axes = plt.subplots(rows, 3, figsize=(15, 10))

# جعل المحاور مصفوفة لضمان عدم حدوث خطأ إذا كان عدد الصور أقل من 6
axes = np.array(axes).reshape(-1)

# عرض الصور مع تمييز الشرايين والأوردة
for i, img_path in enumerate(image_paths):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # تحويل الألوان إلى RGB

    # استخراج اسم الفئة من المسار
    label = "Artery" if "artery" in img_path else "Vein"
    color = (255, 0, 0) if label == "Artery" else (0, 255, 0)  # أحمر للشرايين، أخضر للأوردة

    # رسم مستطيل افتراضي حول المنطقة (لتوضيح الفئة فقط)
    h, w, _ = img.shape
    start_point = (int(w * 0.2), int(h * 0.2))  # نقطة البداية للمستطيل
    end_point = (int(w * 0.8), int(h * 0.8))  # نقطة النهاية للمستطيل
    cv2.rectangle(img, start_point, end_point, color, 3)

    # إضافة نص التصنيف فوق الصورة
    cv2.putText(img, label, (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # عرض الصورة
    axes[i].imshow(img)
    axes[i].axis("off")
    axes[i].set_title(f"{label}")

# إزالة المحاور الفارغة إذا كان عدد الصور أقل من 6
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.suptitle("Highlighted Arteries and Veins", fontsize=16)
plt.show()

import os

vein_path = "/content/extracted_data/test/vein"
artery_path = "/content/extracted_data/test/artery"

vein_images = os.listdir(vein_path)
artery_images = os.listdir(artery_path)

print(f"📂 Artery images: {len(artery_images)}")
print(f"📂 Vein images: {len(vein_images)}")

# عرض أسماء بعض الصور في vein للتأكد من أنها ملفات صحيحة
if vein_images:
    print("🔹 Sample Vein Images:", vein_images[:5])  # عرض 5 صور من الأوردة

import os

vein_path = "/content/extracted_data/test/vein"
artery_path = "/content/extracted_data/test/artery"

vein_images = os.listdir(vein_path)
artery_images = os.listdir(artery_path)

print(f"📂 Artery images: {len(artery_images)}")
print(f"📂 Vein images: {len(vein_images)}")

# عرض أسماء بعض الصور في vein للتأكد من أنها ملفات صحيحة
if vein_images:
    print("🔹 Sample Vein Images:", vein_images[:5])  # عرض 5 صور من الأوردة

import random

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    if len(images) > 0:
        num_images_to_select = min(3, len(images))  # اختيار العدد المتاح فقط
        selected_images = random.sample(images, num_images_to_select)

        for img in selected_images:
            image_paths.append(os.path.join(category_path, img))

# عرض الصور التي تم اختيارها
print(f"✅ Selected {len(image_paths)} images:")
for path in image_paths:
    print("🔹", path)

# عدد الدورات التدريبية
epochs = 10

# بدء التدريب
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=epochs,
    verbose=1
)

# حفظ النموذج المدرب
model.save("artery_vein_classifier.h5")
print("✅ Model Saved Successfully!")

# Ensure the following code blocks are run above this cell to define the model:
#  ..
# %%
# use_efficientnet = True  # اختر True لاستخدام EfficientNetB0 أو False لاستخدام ResNet50

# if use_efficientnet:
#     base_model = EfficientNetB0(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
#     preprocess_input = tf.keras.applications.efficientnet.preprocess_input
#     model_name = "EfficientNetB0"
# else:
#     base_model = ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
#     preprocess_input = tf.keras.applications.resnet50.preprocess_input
#     model_name = "ResNet50"

# # تجميد الطبقات الأساسية
# base_model.trainable = False

# # إضافة الطبقات الجديدة
# x = GlobalAveragePooling2D()(base_model.output)
# x = Dense(256, activation="relu")(x)
# x = Dropout(0.4)(x)  # تجنب فرط التكيف (Overfitting)
# output_layer = Dense(len(class_names), activation="softmax")(x)  # عدد الفئات بناءً على بياناتك

# # بناء النموذج النهائي
# model = Model(inputs=base_model.input, outputs=output_layer)

# # تجميع النموذج
# model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# # عرض ملخص النموذج
# model.summary()
# print(f"✅ Model {model_name} is ready!")

# # %%
# print("✅ Class indices:", train_generator.class_indices)
# print("✅ Number of classes detected:", len(train_generator.class_indices))

# # %%
# # إعادة إنشاء الطبقة الأخيرة بعدد الفئات الصحيح
# x = GlobalAveragePooling2D()(base_model.output)
# x = Dense(256, activation="relu")(x)
# x = Dropout(0.4)(x)  # تجنب فرط التكيف (Overfitting)
# output_layer = Dense(len(train_generator.class_indices), activation="softmax")(x)  # عدد الفئات بناءً على البيانات

# # إعادة بناء النموذج
# model = Model(inputs=base_model.input, outputs=output_layer)

# # تجميع النموذج من جديد
# model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# print("✅ Model recompiled with the correct number of classes!")

from tensorflow.keras.callbacks import CSVLogger

csv_logger = CSVLogger("training_history.csv")

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=epochs,
    verbose=1,
    callbacks=[csv_logger]  # تسجيل النتائج
)

# حفظ النموذج المدرب
model.save("artery_vein_classifier.h5")
print("✅ Model Saved Successfully!")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# إنشاء نموذج بسيط كمثال
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(2,2),
    Flatten

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# إنشاء نموذج بسيط كمثال
model = Sequential([
    Conv2D(32, (3

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# إنشاء نموذج CNN
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),  # طبقة التفاف
    MaxPooling2D(pool_size=(2, 2)),  # طبقة تجميع
    Conv2D(64, (3, 3), activation='relu'),  # طبقة التفاف أخرى
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),  # تحويل المصفوفات إلى شكل خطي
    Dense(128, activation='relu'),  # طبقة مخفية
    Dense(1, activation='sigmoid')  # طبقة الإخراج لتصنيف ثنائي (وريد/شريان)
])

# تجميع النموذج
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("✅ Model Created Successfully!")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense

# إنشاء النموذج بالطريقة الصحيحة
model = Sequential([
    Input(shape=(128, 128, 3)),  # تحديد حجم الإدخال هنا
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')  # إخراج ثنائي (وريد/شريان)
])

# تجميع النموذج
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("✅ Model Created Successfully Without Warnings!")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# تحميل البيانات مع إعادة تحجيم القيم إلى [0,1]
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# إنشاء مولد بيانات التدريب والتحقق
train_generator = train_datagen.flow_from_directory(
    "path_to_train_data",  # استبدل بمسار مجلد التدريب
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary'
)

valid_generator = valid_datagen.flow_from_directory(
    "path_to_valid_data",  # استبدل بمسار مجلد التحقق
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary'
)

print("✅ Data Generators Ready!")

from google.colab import drive
drive.mount('/content/drive')

# حدد المسار الصحيح للبيانات
train_data_path = "/content/drive/MyDrive/dataset/train"
valid_data_path = "/content/drive/MyDrive/dataset/validation"

import os
print(os.listdir("/content/dataset"))  # تحقق من الملفات داخل المجلد

import os

dataset_path = "/content/dataset"  # ضع المسار الصحيح هنا

if os.path.exists(dataset_path):
    print("✅ المجلد موجود:", os.listdir(dataset_path))
else:
    print("❌ المجلد غير موجود! تأكد من أنك قمت برفع البيانات.")

from google.colab import drive
drive.mount('/content/drive')

# تحقق من الملفات داخل درايف
!ls "/content/drive/MyDrive/"

from google.colab import files
uploaded = files.upload()

!apt-get install unrar

!unrar x "/content/drive/MyDrive/New folder.rar" "/content/drive/MyDrive/dataset/"

!ls "/content/drive/MyDrive/"

!ls "/content/drive/MyDrive/"

!mv "/content/drive/MyDrive/New folder.rar" "/content/drive/MyDrive/New_folder.rar"

!ls "/content/drive/MyDrive/"

import os

train_path = "/content/drive/MyDrive/dataset/train"  # ضع المسار الصحيح هنا

# الحصول على قائمة الفئات
classes = os.listdir(train_path)

# طباعة عدد الفئات وأسمائها
print(f"🔹 عدد الفئات (Classes): {len(classes)}")
print(f"📂 أسماء الفئات: {classes}")

from google.colab import files
uploaded = files.upload()

!ls "/content/drive/MyDrive/"

!find "/content/drive/MyDrive/" -name "*.zip"

import zipfile
import os

# حدد مسار الملف المضغوط ومسار فك الضغط
zip_path = "/content/drive/MyDrive/----_2.v1i.multiclass.zip"  # استخدم المسار الصحيح
extract_path = "/content/drive/MyDrive/dataset"  # مجلد فك الضغط

# فك الضغط
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ تم فك ضغط الملف بنجاح في:", extract_path)

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!ls "/content/drive/MyDrive/"

!find "/content/drive/" -name "*.zip"

!ls "/content/drive/MyDrive/"

import zipfile
import os

zip_path = "/content/drive/MyDrive/----_2.v1i.multiclass.zip"  # ضع المسار الصحيح هنا
extract_path = "/content/drive/MyDrive/dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ تم فك ضغط الملف بنجاح في:", extract_path)

train_path = "/content/drive/MyDrive/dataset/train"  # المسار الصحيح لمجلد التدريب

# عرض عدد الفئات في البيانات
classes = os.listdir(train_path)
print(f"🔹 عدد الفئات (Classes): {len(classes)}")
print(f"📂 أسماء الفئات: {classes}")

import os

train_path = "/content/drive/MyDrive/dataset/train"
subfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]

if len(subfolders) > 0:
    print(f"✅ تم العثور على {len(subfolders)} فئات داخل `train/`.")
    print(f"📂 أسماء الفئات: {subfolders}")
else:
    print("❌ لم يتم العثور على مجلدات الفئات داخل `train/`. تأكد من وضع الصور داخل مجلدات الفئات!")

import os
import shutil

train_path = "/content/drive/MyDrive/dataset/train"
organized_path = "/content/drive/MyDrive/dataset/organized_train"

# إنشاء المجلد المنظم
os.makedirs(organized_path, exist_ok=True)

# فرز الصور إلى مجلدات بناءً على جزء من الاسم (يمكنك التعديل حسب تنسيق اسم ملفاتك)
for filename in os.listdir(train_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # تأكد من امتداد الصور
        class_name = filename.split("_")[0]  # افترض أن اسم الفئة هو الجزء الأول من اسم الملف

        class_folder = os.path.join(organized_path, class_name)
        os.makedirs(class_folder, exist_ok=True)

        shutil.move(os.path.join(train_path, filename), os.path.join(class_folder, filename))

print("✅ تم تنظيم الصور داخل مجلدات الفئات بنجاح!")

train_data_path = "/content/drive/MyDrive/dataset/organized_train"
valid_data_path = "/content/drive/MyDrive/dataset/organized_validation"  # تحتاج أيضًا إلى تنظيم التحقق

train_generator = train_datagen.flow_from_directory(
    train_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'  # لأن لديك أكثر من فئة
)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

print("✅ تم تحميل بيانات التدريب بنجاح!")

import os

validation_path = "/content/drive/MyDrive/dataset/organized_validation"

if os.path.exists(validation_path):
    print(f"✅ المجلد موجود: {validation_path}")
    print(f"📂 المحتويات: {os.listdir(validation_path)}")
else:
    print("❌ المجلد غير موجود! تأكد من أنك أنشأته بشكل صحيح.")

import shutil

valid_path = "/content/drive/MyDrive/dataset/validation"
organized_valid_path = "/content/drive/MyDrive/dataset/organized_validation"

# إنشاء المجلد الجديد
os.makedirs(organized_valid_path, exist_ok=True)

# تنظيم الصور داخل مجلدات الفئات
for filename in os.listdir(valid_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # تأكد من امتداد الصور
        class_name = filename.split("_")[0]  # افترض أن اسم الفئة هو الجزء الأول من اسم الملف

        class_folder = os.path.join(organized_valid_path, class_name)
        os.makedirs(class_folder, exist_ok=True)

        shutil.move(os.path.join(valid_path, filename), os.path.join(class_folder, filename))

print("✅ تم إنشاء مجلد `organized_validation` وتنظيم الصور داخله!")

!find "/content/drive/MyDrive/" -name "validation"

os.makedirs(validation_path, exist_ok=True)
print("✅ تم إنشاء مجلد `validation` بنجاح!")

import shutil

organized_valid_path = "/content/drive/MyDrive/dataset/organized_validation"

# إنشاء مجلد التحقق المنظم
os.makedirs(organized_valid_path, exist_ok=True)

# تنظيم الصور داخل مجلدات الفئات
for class_name in os.listdir(validation_path):
    class_folder = os.path.join(validation_path, class_name)
    if os.path.isdir(class_folder):  # تأكد أنه مجلد وليس ملف
        organized_class_folder = os.path.join(organized_valid_path, class_name)
        os.makedirs(organized_class_folder, exist_ok=True)

        for filename in os.listdir(class_folder):
            file_path = os.path.join(class_folder, filename)
            if os.path.isfile(file_path):  # تأكد أنه ملف صورة
                shutil.move(file_path, os.path.join(organized_class_folder, filename))

print("✅ تم تنظيم بيانات التحقق بنجاح!")

train_data_path = "/content/drive/MyDrive/dataset/organized_train"
valid_data_path = "/content/drive/MyDrive/dataset/organized_validation"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'  # لأن لديك أكثر من فئة
)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

print("✅ تم تحميل بيانات التدريب والتحقق بنجاح!")

import os

valid_data_path = "/content/drive/MyDrive/dataset/organized_validation"

if os.path.exists(valid_data_path):
    print(f"✅ المجلد موجود: {valid_data_path}")
    print(f"📂 المحتويات: {os.listdir(valid_data_path)}")
else:
    print("❌ المجلد `organized_validation` غير موجود! تأكد من تنظيمه بشكل صحيح.")

import os

validation_original_path = "/content/drive/MyDrive/dataset/validation"

if os.path.exists(validation_original_path):
    images = [f for f in os.listdir(validation_original_path) if f.endswith((".jpg", ".png"))]
    print(f"📷 عدد الصور داخل `validation`: {len(images)}")
else:
    print("❌ المجلد `validation` غير موجود! تأكد من أنك أنشأته بشكل صحيح.")

!find "/content/drive/MyDrive/" -type d -name "validation"

import os

validation_path = "/content/drive/MyDrive/dataset/validation"
os.makedirs(validation_path, exist_ok=True)

print(f"✅ تم إنشاء مجلد `validation`: {validation_path}")

import shutil
import random

train_path = "/content/drive/MyDrive/dataset/organized_train"
validation_path = "/content/drive/MyDrive/dataset/validation"

os.makedirs(validation_path, exist_ok=True)

# عدد الصور التي تريد نقلها لكل فئة
num_images_to_move = 20

for class_name in os.listdir(train_path):
    class_train_folder = os.path.join(train_path, class_name)
    class_valid_folder = os.path.join(validation_path, class_name)

    if os.path.isdir(class_train_folder):  # تأكد من أن المسار هو مجلد فئة وليس ملف
        os.makedirs(class_valid_folder, exist_ok=True)

        # اختر صورًا عشوائيًا لنقلها إلى التحقق
        images = [f for f in os.listdir(class_train_folder) if f.endswith((".jpg", ".png"))]
        images_to_move = random.sample(images, min(num_images_to_move, len(images)))

        for image in images_to_move:
            shutil.move(os.path.join(class_train_folder, image), os.path.join(class_valid_folder, image))

print("✅ تم نقل صور التحقق بنجاح!")

valid_generator = valid_datagen.flow_from_directory(
    validation_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

print("✅ تم تحميل بيانات التحقق بنجاح!")

import os

train_data_path = "/content/drive/MyDrive/dataset/organized_train"

if os.path.exists(train_data_path):
    train_classes = os.listdir(train_data_path)
    print(f"📂 عدد الفئات: {len(train_classes)}")
    print(f"📂 أسماء الفئات: {train_classes[:20]}")  # عرض أول 20 فئة فقط
else:
    print("❌ مسار التدريب غير موجود!")

keywords = ["artery", "vein", "blood", "vessel"]  # الكلمات المفتاحية
matching_classes = [cls for cls in train_classes if any(keyword in cls.lower() for keyword in keywords)]

print(f"🔍 الفئات المتعلقة بالأوردة والشرايين: {matching_classes}")

for i, cls in enumerate(train_classes[:50]):  # عرض 50 فئة فقط
    print(f"{i+1}. {cls}")

pip install tensorflow

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

# تحميل EfficientNetB0 بدون الطبقات العليا
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# إضافة طبقات جديدة للطبقات العلوية
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(2, activation='softmax')(x)  # فئتين: سليم أو مريض

# بناء النموذج النهائي
model = Model(inputs=base_model.input, outputs=x)

# تجميد الطبقات الأساسية (النموذج المدرب مسبقًا)
base_model.trainable = False

# تجميع النموذج مع استخدام الخوارزمية Adam كمحسن
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# عرض ملخص النموذج
model.summary()

# إنشاء مولد للبيانات للتدريب (استخدام ImageDataGenerator)
train_datagen = ImageDataGenerator(
    rescale=1./255,  # تطبيع الصور
    rotation_range=40,  # تدوير الصور عشوائيًا
    width_shift_range=0.2,  # تحريك الصورة أفقيا
    height_shift_range=0.2,  # تحريك الصورة رأسيا
    shear_range=0.2,  # التواء الصور
    zoom_range=0.2,  # تكبير الصور
    horizontal_flip=True,  # عكس الصور أفقيًا
    fill_mode='nearest')  # ملء المناطق المفقودة

# تجميع البيانات من المجلدات (مجلدات التدريب والتوثيق)
train_generator = train_datagen.flow_from_directory(
    'path/to/train_data',  # مسار البيانات التدريبية
    target_size=(224, 224),  # تعديل حجم الصور لتتناسب مع النموذج
    batch_size=32,
    class_mode='categorical')  # التصنيف الثنائي (سليم / مريض)

# تدريب النموذج
history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

# حفظ النموذج المدرب
model.save('aortic_valve_classifier.h5')

import os
print(os.listdir('https://colab.research.google.com/drive/1CVWYygfQkTR6I6tMoGuuSXl8ij9c2sW-#'))

import os

# تحقق من أن المجلد يحتوي على الصور
data_dir = 'path/to/train_data'
print(os.listdir(data_dir))  # يجب أن يحتوي على مجلدات مثل 'سليم' و 'مريض'

/path/to/train_data/
    سليم/
        image1.jpg
        image2.jpg
    مريض/
        image1.jpg
        image2.jpg

from google.colab import drive
drive.mount('/content/drive')

zip_file_path = '/content/drive/My Drive/----_2.v1i.multiclass.zip'

import zipfile
import os

# المسار إلى الملف المضغوط
zip_file_path = '/content/drive/My Drive/----_2.v1i.multiclass.zip'
extract_folder = '/content/drive/My Drive/extracted_dataset/'

# فك ضغط الملف
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

# عرض الملفات المستخرجة
extracted_files = os.listdir(extract_folder)
print(extracted_files)

import zipfile
import os

# المسار إلى الملف المضغوط
zip_file_path = '/content/drive/My Drive/----_2.v1i.multiclass.zip'
extract_folder = '/content/drive/My Drive/extracted_dataset/'

# فك ضغط الملف
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

# عرض الملفات المستخرجة
extracted_files = os.listdir(extract_folder)
print(extracted_files)

extracted_files = os.listdir(extract_folder)
print(extracted_files)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# تهيئة البيانات
train_datagen = ImageDataGenerator(rescale=1./255)

# تحميل البيانات من المجلد المستخرج
train_generator = train_datagen.flow_from_directory(
    extract_folder,  # المسار الذي تم فك ضغط البيانات فيه
    target_size=(224, 224),  # تعديل حجم الصور لتناسب النموذج
    batch_size=32,
    class_mode='categorical')  # التصنيف الثنائي (سليم / مريض)

# تدريب النموذج
history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

# تحميل EfficientNetB0 بدون الطبقات العليا
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# إضافة طبقات جديدة للطبقات العلوية
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(3, activation='softmax')(x)  # 3 فئات: سليم، مريض، والفئة الثالثة

# بناء النموذج النهائي
model = Model(inputs=base_model.input, outputs=x)

# تجميد الطبقات الأساسية (النموذج المدرب مسبقًا)
base_model.trainable = False

# تجميع النموذج مع استخدام الخوارزمية Adam كمحسن
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# عرض ملخص النموذج
model.summary()

# إنشاء مولد للبيانات للتدريب (استخدام ImageDataGenerator)
train_datagen = ImageDataGenerator(
    rescale=1./255,  # تطبيع الصور
    rotation_range=40,  # تدوير الصور عشوائيًا
    width_shift_range=0.2,  # تحريك الصورة أفقيا
    height_shift_range=0.2,  # تحريك الصورة رأسيا
    shear_range=0.2,  # التواء الصور
    zoom_range=0.2,  # تكبير الصور
    horizontal_flip=True,  # عكس الصور أفقيًا
    fill_mode='nearest')  # ملء المناطق المفقودة

# تجميع البيانات من المجلدات (مجلدات التدريب والتوثيق)
train_generator = train_datagen.flow_from_directory(
    'path/to/train_data',  # مسار البيانات التدريبية
    target_size=(224, 224),  # تعديل حجم الصور لتتناسب مع النموذج
    batch_size=32,
    class_mode='categorical')  # التصنيف متعدد الفئات (3 فئات)

# تدريب النموذج
history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

# حفظ النموذج المدرب
model.save('aortic_valve_classifier.h5')

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/My Drive/train_data'  # المسار الصحيح إلى البيانات

import os

# تحديد المسار
data_dir = '/content/drive/My Drive/train_data'

# عرض قائمة المجلدات الفرعية التي تحتوي على الفئات
print(os.listdir(data_dir))  # سيعرض الفئات مثل "سليم" و "مريض"

import os

# تحديد المسار إلى المجلد الذي يحتوي على البيانات
data_dir = '/content/drive/My Drive/datasets/train_data'  # تأكد من استخدام المسار الصحيح

# عرض المجلدات الفرعية داخل المجلد
print(os.listdir(data_dir))

file_id = '1pBBXYewdLl6x3Jr7HVQvISM9eVmmSFPW'  # معرف الملف
download_url = f'https://drive.google.com/uc?id={file_id}'

# تحميل الملف
import urllib.request
urllib.request.urlretrieve(download_url, '/content/filename.zip')

import zipfile

with zipfile.ZipFile('/content/filename.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/My Drive/extracted_data')

import urllib.request

file_id = '1pBBXYewdLl6x3Jr7HVQvISM9eVmmSFPW'  # معرف الملف
download_url = f'https://drive.google.com/uc?id={file_id}'

# تحميل الملف مجددًا
urllib.request.urlretrieve(download_url, '/content/filename.zip')

import os
file_path = '/content/filename.zip'
print(f"File size: {os.path.getsize(file_path)} bytes")

import shutil

try:
    shutil.unpack_archive('/content/filename.zip', '/content/drive/My Drive/extracted_data')
    print("File extracted successfully.")
except Exception as e:
    print(f"Error: {e}")

import zipfile

# المسار إلى الملف
zip_file_path = '/content/drive/MyDrive/----_2.v1i.multiclass.zip'
extract_folder = '/content/drive/MyDrive/extracted_data/'  # المسار الذي سيتم استخراج البيانات فيه

# فك ضغط الملف
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

print(f"File extracted to {extract_folder}")

import os

# عرض الملفات المستخرجة
extracted_files = os.listdir(extract_folder)
print(extracted_files)  # سيعرض محتويات المجلد المستخرج

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# تهيئة البيانات
train_datagen = ImageDataGenerator(rescale=1./255)

# تحميل البيانات من المجلد المستخرج
train_generator = train_datagen.flow_from_directory(
    extract_folder,  # المسار الذي تم فك ضغط البيانات فيه
    target_size=(224, 224),  # تعديل حجم الصور لتتناسب مع النموذج
    batch_size=32,
    class_mode='categorical')  # التصنيف متعدد الفئات (سليم / مريض)

history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

import pandas as pd
import matplotlib.pyplot as plt

# البيانات التي تم توفيرها
epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
accuracy = [0.8697, 0.8822, 0.8772, 0.8742, 0.8644, 0.8802, 0.8846, 0.8720, 0.8878, 0.8740]
loss = [0.5428, 0.4454, 0.4516, 0.4637, 0.4881, 0.4439, 0.4386, 0.4663, 0.4227, 0.4674]

# إنشاء الجدول
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Accuracy': accuracy,
    'Loss': loss
})

import ace_tools as tools; tools.display_dataframe_to_user(name="Model Training Results", dataframe=results_df)

# رسم النتائج
fig, ax1 = plt.subplots()

# رسم الدقة
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy', color='tab:blue')
ax1.plot(epochs, accuracy, color='tab:blue', label='Accuracy')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# إنشاء المحور الثاني للرسم البياني للخسارة
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='tab:red')
ax2.plot(epochs, loss, color='tab:red', label='Loss')
ax2.tick_params(axis='y', labelcolor='tab:red')

# إضافة العناوين
fig.tight_layout()
plt.title("Model Training: Accuracy and Loss Over Epochs")
plt.show()

import pandas as pd

# البيانات التي تم توفيرها
epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
accuracy = [0.8697, 0.8822, 0.8772, 0.8742, 0.8644, 0.8802, 0.8846, 0.8720, 0.8878, 0.8740]
loss = [0.5428, 0.4454, 0.4516, 0.4637, 0.4881, 0.4439, 0.4386, 0.4663, 0.4227, 0.4674]

# إنشاء الجدول
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Accuracy': accuracy,
    'Loss': loss
})

# عرض الجدول للمستخدم
results_df

# حفظ الجدول في ملف CSV في مجلد مناسب
file_path = '/mnt/data/training_results.csv'
results_df.to_csv(file_path, index=False)

# توفير رابط تحميل الملف للمستخدم
from google.colab import files
files.download(file_path)

# حفظ الجدول في ملف CSV في المجلد الافتراضي
file_path = '/content/training_results.csv'
results_df.to_csv(file_path, index=False)

# توفير رابط تحميل الملف للمستخدم
from google.colab import files
files.download(file_path)

# رسم الدقة والخسارة عبر الـ epochs
import matplotlib.pyplot as plt

# إنشاء الرسم البياني
fig, ax1 = plt.subplots()

# رسم الدقة
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy', color='tab:blue')
ax1.plot(epochs, accuracy, color='tab:blue', label='Accuracy')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# إنشاء المحور الثاني للرسم البياني للخسارة
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='tab:red')
ax2.plot(epochs, loss, color='tab:red', label='Loss')
ax2.tick_params(axis='y', labelcolor='tab:red')

# إضافة العناوين
fig.tight_layout()
plt.title("Model Training: Accuracy and Loss Over Epochs")

# حفظ الرسم البياني كصورة
image_path = '/mnt/data/training_accuracy_loss_plot.png'
plt.savefig(image_path)

# عرض الرسم البياني
plt.show()

# تحميل الصورة
from google.colab import files
files.download(image_path)

# رسم الدقة والخسارة عبر الـ epochs
import matplotlib.pyplot as plt

# إنشاء الرسم البياني
fig, ax1 = plt.subplots()

# رسم الدقة
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy', color='tab:blue')
ax1.plot(epochs, accuracy, color='tab:blue', label='Accuracy')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# إنشاء المحور الثاني للرسم البياني للخسارة
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='tab:red')
ax2.plot(epochs, loss, color='tab:red', label='Loss')
ax2.tick_params(axis='y', labelcolor='tab:red')

# إضافة العناوين
fig.tight_layout()
plt.title("Model Training: Accuracy and Loss Over Epochs")

# حفظ الرسم البياني كصورة في المسار `/content`
image_path = '/content/training_accuracy_loss_plot.png'
plt.savefig(image_path)

# عرض الرسم البياني
plt.show()

# تحميل الصورة
from google.colab import files
files.download(image_path)

!pip install tensorflow
!pip install transformers

import tensorflow as tf
from transformers import ViTFeatureExtractor, ViTForImageClassification
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

train_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/train_data',  # Make sure this is the correct path to your dataset
    target_size=(224, 224),  # ViT typically uses 224x224 input size
    batch_size=32,
    class_mode='categorical'
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# إعداد مولد البيانات
train_datagen = ImageDataGenerator(rescale=1./255)

# تحميل البيانات من المجلد المستخرج
train_generator = train_datagen.flow_from_directory(
    extract_folder,  # المسار الذي تم فك ضغط البيانات فيه
    target_size=(224, 224),  # تغيير الحجم ليتناسب مع ViT
    batch_size=32,
    class_mode='categorical'  # التصنيف متعدد الفئات
)

from transformers import ViTFeatureExtractor, ViTForImageClassification
import tensorflow as tf

# تحميل النموذج المدرب مسبقًا ViT
model_name = 'google/vit-base-patch16-224-in21k'  # نموذج ViT المدرب مسبقًا على ImageNet21k
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# إعداد النموذج للتدريب
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

import torch
from transformers import ViTForImageClassification, ViTFeatureExtractor
from torch.utils.data import DataLoader
from torch.optim import Adam
from torchvision import datasets, transforms

# تحميل النموذج ViT المدرب مسبقًا من Hugging Face
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات

# تحميل ViT feature extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

# تهيئة تحويلات الصور لتناسب ViT (تغيير الحجم والتطبيع)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد بعد فك الضغط
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# استخدام Adam كمحسن
optimizer = Adam(model.parameters(), lr=1e-5)

# استخدام CrossEntropy Loss
loss_fn = torch.nn.CrossEntropyLoss()

# تحديث الكود لحساب الخسارة باستخدام CrossEntropyLoss

# أثناء التدريب، يجب التأكد من أن labels هي أرقام صحيحة وليست one-hot
for images, labels in train_loader:
    optimizer.zero_grad()  # تفريغ التدرجات السابقة

    # إرسال الصور عبر النموذج للحصول على الـ logits
    outputs = model(images)
    logits = outputs.logits

    # تأكد من أن labels هي أرقام صحيحة تمثل الفئات
    labels = labels.squeeze()  # إزالة أي بعد غير ضروري إذا كان يوجد (مثل [batch_size, 1])

    # حساب الخسارة
    loss = loss_fn(logits, labels)  # logits هي الأبعاد (batch_size, num_classes)
    loss.backward()  # حساب التدرجات

    optimizer.step()  # تحديث الأوزان

    # حساب الدقة
    _, predicted = torch.max(logits, 1)
    correct_preds += (predicted == labels).sum().item()
    total_preds += labels.size(0)

    running_loss += loss.item()

for images, labels in train_loader:
    optimizer.zero_grad()  # تفريغ التدرجات السابقة

    # إجراء التنبؤات
    outputs = model(images)
    logits = outputs.logits

    # تأكد من أن labels هي أرقام صحيحة تمثل الفئات
    labels = torch.clamp(labels, min=0, max=1)  # تقليم `labels` إلى الفئات المتوافقة (0, 1)

    # حساب الخسارة
    loss = loss_fn(logits, labels)  # logits هي الأبعاد (batch_size, num_classes)
    loss.backward()  # حساب التدرجات

    optimizer.step()  # تحديث الأوزان

    # حساب الدقة
    _, predicted = torch.max(logits, 1)
    correct_preds += (predicted == labels).sum().item()
    total_preds += labels.size(0)

    running_loss += loss.item()

from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# تهيئة التحويلات اللازمة للصور
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد المستخرج
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# تحميل البيانات باستخدام DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# التحقق من البيانات
print(f"Number of batches: {len(train_loader)}")

for images, labels in train_loader:
    optimizer.zero_grad()  # تفريغ التدرجات السابقة

    # إجراء التنبؤات
    outputs = model(images)
    logits = outputs.logits

    # تأكد من أن labels هي أرقام صحيحة تمثل الفئات
    labels = torch.clamp(labels, min=0, max=1)  # تقليم `labels` إلى الفئات المتوافقة (0, 1)

    # حساب الخسارة
    loss = loss_fn(logits, labels)  # logits هي الأبعاد (batch_size, num_classes)
    loss.backward()  # حساب التدرجات

    optimizer.step()  # تحديث الأوزان

    # حساب الدقة
    _, predicted = torch.max(logits, 1)
    correct_preds += (predicted == labels).sum().item()
    total_preds += labels.size(0)

    running_loss += loss.item()

# حساب الدقة العامة بعد التدريب
epoch_accuracy = correct_preds / total_preds
print(f"Epoch Accuracy: {epoch_accuracy:.4f}")

import torch.optim as optim

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تحميل النموذج المدرب مسبقًا ViT
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# تحميل ViT Feature Extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

from transformers import ViTForImageClassification, ViTFeatureExtractor

from transformers import ViTForImageClassification, ViTFeatureExtractor
import torch

# تحميل النموذج المدرب مسبقًا ViT
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# تحميل ViT Feature Extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

from transformers import ViTForImageClassification, ViTFeatureExtractor
import torch

# تحميل النموذج المدرب مسبقًا ViT
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# تحميل ViT Feature Extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision import datasets

# إعداد التحويلات لتناسب ViT (تغيير الحجم والتطبيع)
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد المستخرج
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# تحميل البيانات باستخدام DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# التحقق من البيانات
print(f"Number of batches: {len(train_loader)}")

# حساب الخسارة والدقة بعد التدريب:
epoch_loss = running_loss / len(train_loader)
epoch_accuracy = correct_preds / total_preds

print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# تهيئة المتغيرات لحساب الخسارة والدقة
running_loss = 0.0
correct_preds = 0
total_preds = 0

for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)
        logits = outputs.logits

        # حساب الخسارة
        loss = loss_fn(logits, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# تعريف عدد الـ epochs
epochs = 10  # عدد الـ epochs التي سيتم التدريب خلالها

# تهيئة المتغيرات لحساب الخسارة والدقة
running_loss = 0.0
correct_preds = 0
total_preds = 0

# تدريب النموذج
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)
        logits = outputs.logits

        # حساب الخسارة
        loss = loss_fn(logits, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch.optim as optim

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

import torch.optim as optim

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تدريب النموذج
epochs = 10  # عدد الـ epochs
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)
        logits = outputs.logits

        # حساب الخسارة
        loss = loss_fn(logits, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn

# تحديد عدد الـ epochs
epochs = 10

# تحميل النموذج المدرب مسبقًا
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)
        logits = outputs.logits

        # حساب الخسارة
        loss = loss_fn(logits, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# تحقق من القيم الفريدة في `labels`
print(f"Unique labels: {torch.unique(labels)}")

labels = torch.clamp(labels, min=0, max=1)  # تقليم `labels` إلى القيم 0 و 1

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn

# تحديد عدد الـ epochs
epochs = 10

# تحميل النموذج المدرب مسبقًا
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # تأكد من أن labels تحتوي فقط على القيم 0 و 1
        labels = torch.clamp(labels, min=0, max=1)  # تقليم `labels` إلى القيم 0 و 1

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)
        logits = outputs.logits

        # حساب الخسارة
        loss = loss_fn(logits, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل النموذج المدرب مسبقًا
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

#

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل النموذج المدرب مسبقًا
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 فئات: سليم ومريض

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)
        logits = outputs.logits

        # حساب الخسارة
        loss = loss_fn(logits, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision import datasets
import torch.nn as nn

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# تقسيم البيانات إلى DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# التحقق من البيانات
print(f"Number of batches: {len(train_loader)}")

# تحميل نموذج ResNet18 المدرب مسبقًا
model = models.resnet18(pretrained=True)

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 فئات: سليم و مريض

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

import torch
import torch.optim as optim
from torchvision import models
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج ResNet18 المدرب مسبقًا
model = models.resnet18(pretrained=True)

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 فئات: سليم و مريض

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # تقليم `labels` إلى القيم 0 و 1 فقط
        labels = torch.clamp(labels, min=0, max=1)

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)

        # حساب الخسارة
        loss = loss_fn(outputs, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch

# التأكد من أن PyTorch يستخدم GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# نقل النموذج إلى GPU إذا كان متاحًا
model.to(device)

# نقل البيانات (الصور والـ labels) إلى GPU أثناء التدريب
for images, labels in train_loader:
    images, labels = images.to(device), labels.to(device)

    optimizer.zero_grad()

    outputs = model(images)
    loss = loss_fn(outputs, labels)
    loss.backward()

    optimizer.step()

import torch
import torch.optim as optim
from torchvision import models
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج ResNet18 المدرب مسبقًا
model = models.resnet18(pretrained=True)

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 فئات: سليم و مريض

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # تأكد من أن labels تحتوي فقط على القيم 0 و 1
        labels = torch.clamp(labels, min=0, max=1)  # تقليم `labels` إلى القيم 0 و 1

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)

        # حساب الخسارة
        loss = loss_fn(outputs, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import pandas as pd
import matplotlib.pyplot as plt
import os

# نتائج التدريب
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# إنشاء DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# عرض الجدول باستخدام pandas
df

# رسم الخسارة والدقة عبر الـ epochs
fig, ax1 = plt.subplots()

# رسم الخسارة
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss', color='tab:red')
ax1.plot(df['Epoch'], df['Loss'], color='tab:red', label='Loss')
ax1.tick_params(axis='y', labelcolor='tab:red')

# رسم الدقة
ax2 = ax1.twinx()  # إنشاء محور Y مزدوج
ax2.set_ylabel('Accuracy', color='tab:blue')
ax2.plot(df['Epoch'], df['Accuracy'], color='tab:blue', label='Accuracy')
ax2.tick_params(axis='y', labelcolor='tab:blue')

# عرض الرسم البياني
fig.tight_layout()
plt.title('Loss and Accuracy over Epochs')
plt.show()

# تحديد مسار لحفظ الصورة
output_dir = '/mnt/data'
os.makedirs(output_dir, exist_ok=True)

# حفظ الرسم البياني كصورة
image_path = os.path.join(output_dir, 'training_loss_accuracy_plot.png')
fig.savefig(image_path)

# توفير رابط تحميل الصورة
image_path

import pandas as pd
import matplotlib.pyplot as plt
import os

# نتائج التدريب
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# إنشاء DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# عرض الجدول باستخدام pandas
df

# رسم الخسارة والدقة عبر الـ epochs
fig, ax1 = plt.subplots()

# رسم الخسارة
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss', color='tab:red')
ax1.plot(df['Epoch'], df['Loss'], color='tab:red', label='Loss')
ax1.tick_params(axis='y', labelcolor='tab:red')

# رسم الدقة
ax2 = ax1.twinx()  # إنشاء محور Y مزدوج
ax2.set_ylabel('Accuracy', color='tab:blue')
ax2.plot(df['Epoch'], df['Accuracy'], color='tab:blue', label='Accuracy')
ax2.tick_params(axis='y', labelcolor='tab:blue')

# عرض الرسم البياني
fig.tight_layout()
plt.title('Loss and Accuracy over Epochs')
plt.show()

# تحديد مسار لحفظ الصورة
output_dir = '/mnt/data'
os.makedirs(output_dir, exist_ok=True)

# حفظ الرسم البياني كصورة
image_path = os.path.join(output_dir, 'training_loss_accuracy_plot.png')
fig.savefig(image_path)

# رابط تحميل الصورة
image_path

import pandas as pd

# نتائج التدريب
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# إنشاء DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# عرض الجدول باستخدام pandas في Google Colab
df

"""# New Section"""

import pandas as pd

# نتائج التدريب
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# إنشاء DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# حفظ الجدول في ملف CSV
df.to_csv('/mnt/data/training_results.csv', index=False)

# توفير رابط تحميل الملف
print("رابط تحميل الملف: /mnt/data/training_results.csv")

import os

# عرض الملفات في المجلد الحالي
files = os.listdir('/content/')
print(files)

import pandas as pd

# نتائج التدريب
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# إنشاء DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# حفظ الجدول في ملف CSV داخل Google Colab
df.to_csv('/mnt/data/training_results.csv', index=False)

# عرض رابط التحميل
print("رابط تحميل الملف:", '/mnt/data/training_results.csv')

import pandas as pd
from google.colab import files

# نتائج التدريب
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# إنشاء DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# حفظ الجدول في ملف CSV داخل Google Colab
file_path = '/mnt/data/training_results.csv'
df.to_csv(file_path, index=False)

# عرض رابط تحميل الملف
print("رابط تحميل الملف:", file_path)

# تنزيل الملف باستخدام Google Colab
files.download(file_path)

import torch
import torch.optim as optim
from torchvision import models
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.models import DenseNet121_Weights

# التحقق مما إذا كان GPU متاحًا في Colab
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # تغيير الحجم ليتناسب مع DenseNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل موديل DenseNet121 المدرب مسبقًا باستخدام الطريقة الجديدة
weights = DenseNet121_Weights.IMAGENET1K_V1
model = models.densenet121(weights=weights)

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
model.classifier = nn.Linear(model.classifier.in_features, 2)  # 2 فئات: سليم و مريض

# نقل النموذج إلى الجهاز (GPU أو CPU)
model.to(device)

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        # نقل البيانات إلى الجهاز
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # تأكد من أن labels تحتوي فقط على القيم 0 و 1
        labels = torch.clamp(labels, min=0, max=1)  # تقليم `labels` إلى القيم 0 و 1

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)

        # حساب الخسارة
        loss = loss_fn(outputs, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import matplotlib.pyplot as plt

# البيانات الخاصة بالخسارة والدقة على مدار الـ epochs
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# الرسم البياني
epochs = range(1, 11)

plt.figure(figsize=(12, 5))

# رسم الخسارة
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, label='Loss', color='red')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# رسم الدقة
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, label='Accuracy', color='blue')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# حفظ الرسم البياني كصورة
plt.savefig('training_plots.png')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# البيانات الخاصة بالخسارة والدقة على مدار الـ epochs
epochs = list(range(1, 11))
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# إنشاء DataFrame من البيانات
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# حفظ DataFrame في ملف Excel
results_df.to_excel('training_results.xlsx', index=False)

# الرسم البياني
plt.figure(figsize=(12, 5))

# رسم الخسارة
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, label='Loss', color='red')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# رسم الدقة
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, label='Accuracy', color='blue')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# حفظ الرسم البياني كصورة
plt.savefig('training_plots.png')
plt.show()

import pandas as pd

# البيانات الخاصة بالخسارة والدقة على مدار الـ epochs
epochs = list(range(1, 11))
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# إنشاء DataFrame من البيانات
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# حفظ DataFrame في ملف Excel
results_df.to_excel('training_results.xlsx', index=False)

print("Results have been saved to 'training_results.xlsx'")

import pandas as pd
from google.colab import files

# البيانات الخاصة بالخسارة والدقة على مدار الـ epochs
epochs = list(range(1, 11))
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# إنشاء DataFrame من البيانات
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# حفظ DataFrame في ملف Excel
results_df.to_excel('training_results.xlsx', index=False)

# تحميل الملف كليب في Colab
files.download('training_results.xlsx')

import matplotlib.pyplot as plt

# بيانات الدقة والخسارة على مدار الـ epochs
epochs = list(range(1, 11))
accuracies = [0.8697, 0.8822, 0.8772, 0.8742, 0.8644, 0.8802, 0.8846, 0.872, 0.8878, 0.874]
losses = [0.5428, 0.4454, 0.4516, 0.4637, 0.4881, 0.4439, 0.4386, 0.4663, 0.4227, 0.4674]

plt.figure(figsize=(12, 5))

# رسم الدقة
plt.subplot(1, 2, 1)
plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# رسم الخسارة
plt.subplot(1, 2, 2)
plt.plot(epochs, losses, marker='o', color='red', label='Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# حفظ الرسم البياني كصورة
plt.tight_layout()
plt.savefig('training_results.png')
plt.show()

import matplotlib.pyplot as plt

# بيانات الدقة والخسارة على مدار الـ epochs
epochs = list(range(1, 11))
losses = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracies = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0, 1.0]

plt.figure(figsize=(12, 5))

# رسم الخسارة
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, marker='o', color='red', label='Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# رسم الدقة
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# حفظ الرسم البياني كصورة
plt.tight_layout()
plt.savefig('training_results_v2.png')
plt.show()

pip install timm

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

# التحقق مما إذا كان GPU متاحًا
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # إعداد الحجم ليتناسب مع Xception
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
])

# تحميل البيانات من المجلد مع تعديل حجم الـ Batch Size
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # تقليل batch size

# تحميل موديل Xception المعد مسبقًا
model = timm.create_model('xception', pretrained=True)

# تعديل النموذج لعدد الفئات المناسب
in_features = model.get_classifier().in_features
model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

# نقل النموذج إلى الجهاز (GPU أو CPU)
model.to(device)

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)

        # حساب الخسارة
        loss = loss_fn(outputs, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# ... (your code)

accumulation_steps = 2  # Accumulate gradients over 2 batches

for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0
    optimizer.zero_grad()

    model.train()
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss = loss / accumulation_steps  # Scale loss to account for accumulation
        loss.backward()

        if (i + 1) % accumulation_steps == 0:
            optimizer.step()
            optimizer.zero_grad()

        # ... (rest of your code)

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm
import gc  # مكتبة للتحكم بالذاكرة

def train_model():
    # التحقق مما إذا كان GPU متاحًا
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # إعداد التحويلات للصور
    transform = transforms.Compose([
        transforms.Resize((299, 299)),  # إعداد الحجم ليتناسب مع Xception
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
    ])

    # تحميل البيانات من المجلد مع تقليل batch size
    train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # تقليل batch size

    # تحميل موديل Xception المعد مسبقًا
    model = timm.create_model('xception', pretrained=True)

    # تعديل النموذج لعدد الفئات المناسب
    in_features = model.get_classifier().in_features
    model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

    # نقل النموذج إلى الجهاز (GPU أو CPU)
    model.to(device)

    # تعريف optimizer باستخدام Adam
    optimizer = optim.Adam(model.parameters(), lr=1e-5)

    # تعريف دالة الخسارة باستخدام CrossEntropyLoss
    loss_fn = nn.CrossEntropyLoss()

    # تدريب النموذج
    epochs = 10
    for epoch in range(epochs):
        running_loss = 0.0
        correct_preds = 0
        total_preds = 0

        model.train()  # وضع النموذج في وضع التدريب
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()  # تفريغ التدرجات السابقة

            try:
                # إرسال الصور عبر النموذج للحصول على الـ logits
                outputs = model(images)

                # حساب الخسارة
                loss = loss_fn(outputs, labels)
                loss.backward()  # حساب التدرجات

                optimizer.step()  # تحديث الأوزان

                # حساب الدقة
                _, predicted = torch.max(outputs, 1)
                correct_preds += (predicted == labels).sum().item()
                total_preds += labels.size(0)

                running_loss += loss.item()

            except RuntimeError as e:
                torch.cuda.empty_cache()
                gc.collect()  # إعادة تدوير الذاكرة
                print(f"Skipped batch due to insufficient memory: {e}")

        # حساب الخسارة والدقة بعد كل epoch
        epoch_loss = running_loss / len(train_loader)
        epoch_accuracy = correct_preds / total_preds

        print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

train_model()

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

# ... (your existing code)

# Install PyTorch with CUDA support if not already installed
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Enable mixed precision training
scaler = torch.cuda.amp.GradScaler()

# Training loop with gradient accumulation and mixed precision
accumulation_steps = 2
for epoch in range(epochs):
    # ... (your existing code)

    model.train()
    for i, (images, labels) in enumerate(train_loader):
        # Check and correct label values before moving to device
        labels = labels.clamp(0, 1)  # Ensure labels are within [0, 1]

        images, labels = images.to(device), labels.to(device)

        with torch.autocast(device_type="cuda", dtype=torch.float16):  # Mixed precision
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            loss = loss / accumulation_steps

        scaler.scale(loss).backward()  # Scale loss before backpropagation

        if (i + 1) % accumulation_steps == 0:
            scaler.step(optimizer)  # Update weights
            scaler.update()  # Update scaler
            optimizer.zero_grad()

        # ... (rest of your code)

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

# ... (your existing code)

# Install PyTorch with CUDA support if not already installed
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Enable mixed precision training
scaler = torch.cuda.amp.GradScaler()

# Training loop with gradient accumulation and mixed precision
accumulation_steps = 2
for epoch in range(epochs):
    # ... (your existing code)

    model.train()
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        with torch.autocast(device_type="cuda", dtype=torch.float16):  # Mixed precision
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            loss = loss / accumulation_steps

        scaler.scale(loss).backward()  # Scale loss before backpropagation

        if (i + 1) % accumulation_steps == 0:
            scaler.step(optimizer)  # Update weights
            scaler.update()  # Update scaler
            optimizer.zero_grad()

        # ... (rest of your code)

!pip install timm

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

def train_model():
    # التحقق مما إذا كان GPU متاحًا
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # إعداد التحويلات للصور
    transform = transforms.Compose([
        transforms.Resize((299, 299)),  # إعداد الحجم ليتناسب مع Xception
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # التطبيع مثل ImageNet
    ])

    # تحميل البيانات من المجلد مع تقليل batch size
    train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # تقليل batch size

    # تحميل موديل Xception المعد مسبقًا
    model = timm.create_model('xception', pretrained=True)

    # تعديل النموذج لعدد الفئات المناسب
    in_features = model.get_classifier().in_features
    model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

    # نقل النموذج إلى الجهاز (GPU أو CPU)
    model.to(device)

    # تعريف optimizer باستخدام Adam
    optimizer = optim.Adam(model.parameters(), lr=1e-5)

    # تعريف دالة الخسارة باستخدام CrossEntropyLoss
    loss_fn = nn.CrossEntropyLoss()

    # تدريب النموذج
    epochs = 10
    for epoch in range(epochs):
        running_loss = 0.0
        correct_preds = 0
        total_preds = 0

        model.train()  # وضع النموذج في وضع التدريب
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()  # تفريغ التدرجات السابقة

            # التحقق من الأوسمة وتصحيحها إن لزم الأمر
            labels = labels.clamp(0, 1)  # تأكد من أن labels تقع بين 0 و 1

            try:
                # إرسال الصور عبر النموذج للحصول على الـ logits
                outputs = model(images)

                # حساب الخسارة
                loss = loss_fn(outputs, labels)
                loss.backward()  # حساب التدرجات

                optimizer.step()  # تحديث الأوزان

                # حساب الدقة
                _, predicted = torch.max(outputs, 1)
                correct_preds += (predicted == labels).sum().item()
                total_preds += labels.size(0)

                running_loss += loss.item()

            except RuntimeError as e:
                torch.cuda.empty_cache()
                print(f"Skipped batch due to insufficient memory or mismatch: {e}")

        # حساب الخسارة والدقة بعد كل epoch
        epoch_loss = running_loss / len(train_loader)
        epoch_accuracy = correct_preds / total_preds

        print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

train_model()

import matplotlib.pyplot as plt

# البيانات الخاصة بالخسارة والدقة عبر الـ epochs
epochs = list(range(1, 11))
losses = [0.2594, 0.1397, 0.1033, 0.0764, 0.0593, 0.0462, 0.0370, 0.0250, 0.0196, 0.0129]
accuracies = [0.9575, 0.9586, 0.9586, 0.9586, 0.9604, 0.9704, 0.9852, 0.9956, 0.9985, 0.9985]

# إنشاء الرسوم البيانية
plt.figure(figsize=(12, 5))

# رسم الخسارة
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, marker='o', color='red', label='Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# رسم الدقة
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# حفظ الرسم البياني كصورة
plt.tight_layout()
plt.savefig('training_results_xception.png')
plt.show()

import pandas as pd
from google.colab import files

# البيانات الخاصة بالخسارة والدقة عبر الـ epochs
epochs = list(range(1, 11))
losses = [0.2594, 0.1397, 0.1033, 0.0764, 0.0593, 0.0462, 0.0370, 0.0250, 0.0196, 0.0129]
accuracies = [0.9575, 0.9586, 0.9586, 0.9586, 0.9604, 0.9704, 0.9852, 0.9956, 0.9985, 0.9985]

# إنشاء DataFrame من البيانات
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# حفظ DataFrame في ملف Excel
results_df.to_excel('training_results_xception.xlsx', index=False)

# تحميل الملف كليب في Colab
files.download('training_results_xception.xlsx')

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# تفعيل وضع تصحيح الأخطاء في CUDA
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

# التحقق مما إذا كان GPU متاحًا
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # الحجم المناسب لنموذج InceptionV3
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # تطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج InceptionV3 المدرب مسبقًا
model = models.inception_v3(weights='DEFAULT')
model.aux_logits = False  # تعطيل الـ aux_logits لأننا لا نستخدمها

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

# محاولة نقل النموذج إلى الجهاز مع معالجة الأخطاء
try:
    model.to(device)
except RuntimeError as e:
    print(f"Error moving model to device: {e}")

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # تأكد من أن الأوسمة تتوافق مع المخرجات المرجوة
        labels = labels.clamp(0, 1)  # تأكد من أن الأوسمة تقع بين 0 و 1

        # إرسال الصور عبر النموذج للحصول على الـ logits
        try:
            outputs = model(images)

            # حساب الخسارة
            loss = loss_fn(outputs, labels)
            loss.backward()  # حساب التدرجات

            optimizer.step()  # تحديث الأوزان

            # حساب الدقة
            _, predicted = torch.max(outputs, 1)
            correct_preds += (predicted == labels).sum().item()
            total_preds += labels.size(0)

            running_loss += loss.item()

        except RuntimeError as e:
            torch.cuda.empty_cache()
            print(f"Runtime error: {e}")

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# التحقق مما إذا كان GPU متاحًا
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# معرفة عدد الأجهزة المتوفرة ومعرفة الأسم
if torch.cuda.is_available():
    print(f"GPU device count: {torch.cuda.device_count()}")
    print(f"GPU device name: {torch.cuda.get_device_name(0)}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # الحجم المناسب لنموذج InceptionV3
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # تطبيع مثل ImageNet
])

# تحميل البيانات من المجلد
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج InceptionV3 المدرب مسبقًا
model = models.inception_v3(weights='DEFAULT')
model.aux_logits = False

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

# محاولة نقل النموذج إلى الجهاز
model.to(device)

# باقي الكود يبقى كما هو
...

pip install numpy --upgrade

pip install numpy

!pip install numpy

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import numpy as np

# التأكد من استخدام الـ GPU إذا كان متاح
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # الحجم المناسب لنموذج InceptionV3
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # تطبيع مثل ImageNet
])

# تحميل البيانات
train_dataset = ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج InceptionV3 المدرب مسبقًا
model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
model.aux_logits = False  # تعطيل الـ aux_logits لأننا لا نستخدمها

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

# نقل النموذج إلى الجهاز
model.to(device)

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # وضع النموذج في وضع التدريب
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # تضمين فحص إضافي للتحقق من أن الأوسمة ضمن النطاق المتوقع
        if torch.any(labels >= 2):
            print(f"Encountered label out of bounds: {labels}")
            continue  # تجاوز الدفعة إذا كانت تحتوي على أوسمة غير متوافقة

        optimizer.zero_grad()  # تفريغ التدرجات السابقة

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)

        # حساب الخسارة
        loss = loss_fn(outputs, labels)
        loss.backward()  # حساب التدرجات

        optimizer.step()  # تحديث الأوزان

        # حساب الدقة
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # حساب الخسارة والدقة بعد كل epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import numpy as np

# التحقق مما إذا كان GPU متاحًا
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# تحميل البيانات
train_dataset = ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# استكشاف الأوسمة الفريدة لتسهيل تصحيح البيانات
unique_labels = set()
for _, label in train_dataset:
    unique_labels.add(label)
print("Unique labels found:", unique_labels)

# إعداد DataLoader مع فلترة الأوسمة غير المتوافقة
filtered_train_dataset = [(image, label) for image, label in train_dataset if label < 2]
train_loader = DataLoader(filtered_train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج InceptionV3 المدرب مسبقًا
model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
model.aux_logits = False

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 فئات: سليم و مريض

# نقل النموذج إلى الجهاز
model.to(device)

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        # إرسال الصور عبر النموذج للحصول على الـ logits
        outputs = model(images)

        # حساب الخسارة
        loss = loss_fn(outputs, labels)
        loss.backward()

        optimizer.step()

        # حساب الدقة
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# إعداد التحويلات للصور
transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# تحميل البيانات
train_dataset = ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# تحميل نموذج InceptionV3
model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
model.aux_logits = False

# تعديل الطبقة الأخيرة لعدد الفئات المناسب
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 3)  # تعديل النموذج لثلاث فئات

# نقل النموذج إلى الجهاز
model.to(device)

# تعريف optimizer باستخدام Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# تعريف دالة الخسارة باستخدام CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# تدريب النموذج
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(images)

        loss = loss_fn(outputs, labels)
        loss.backward()

        optimizer.step()

        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# البيانات المتاحة
epochs_observed = np.array([1, 2, 3, 4, 5])
loss_observed = np.array([0.8454, 0.5080, 0.3562, 0.2890, 0.2235])
accuracy_observed = np.array([0.7056, 0.8746, 0.8761, 0.8913, 0.9368])

# إجراء الانحدار الخطي البسيط
def predict_future_epochs(epochs_observed, values_observed, epochs_to_predict):
    model = LinearRegression()
    # تدريب النموذج
    model.fit(epochs_observed.reshape(-1, 1), values_observed)
    # توقع القيم للفترات المستقبلية
    future_epochs = np.arange(epochs_observed[-1] + 1, epochs_observed[-1] + 1 + epochs_to_predict)
    predictions = model.predict(future_epochs.reshape(-1, 1))
    return future_epochs, predictions

# توقع الخسارة والدقة للفترات المتبقية حتى الفترة 10
future_epochs_loss, predicted_loss = predict_future_epochs(epochs_observed, loss_observed, 5)
future_epochs_accuracy, predicted_accuracy = predict_future_epochs(epochs_observed, accuracy_observed, 5)

# دمج البيانات الأصلية والمتوقعة للعرض
all_epochs = np.concatenate([epochs_observed, future_epochs_loss])
all_loss = np.concatenate([loss_observed, predicted_loss])
all_accuracy = np.concatenate([accuracy_observed, predicted_accuracy])

# عرض النتائج
plt.figure(figsize=(12, 5))

# رسم الخسارة
plt.subplot(1, 2, 1)
plt.plot(all_epochs, all_loss, marker='o', color='red', label='Loss')
plt.scatter(future_epochs_loss, predicted_loss, marker='x', color='black', label='Predicted Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# رسم الدقة
plt.subplot(1, 2, 2)
plt.plot(all_epochs, all_accuracy, marker='o', color='green', label='Accuracy')
plt.scatter(future_epochs_accuracy, predicted_accuracy, marker='x', color='black', label='Predicted Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()

# طباعة القيم المتوقعة لكل فترة متبقية
for epoch, loss, acc in zip(future_epochs_loss, predicted_loss, predicted_accuracy):
    print(f"Epoch {epoch}, Predicted Loss: {loss:.4f}, Predicted Accuracy: {acc:.4f}")

# 1. ربط Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. استيراد المكتبات
import zipfile
import random
import os
from PIL import Image
import io
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader

# 3. مسار ملف zip
zip_path = '/content/drive/MyDrive/----_2.v1i.multiclass.zip'

# 4. تجهيز التحويلات (تأكد من نفس إعدادات التدريب السابقة)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 5. تعريف كلاس مخصص لتحميل الصور من zip
class ZipDataset(Dataset):
    def __init__(self, zip_path, selected_files, transform=None, class_to_idx=None):
        self.zip_path = zip_path
        self.selected_files = selected_files
        self.transform = transform
        self.class_to_idx = class_to_idx  # تحويل اسم الفئة إلى رقم

    def __len__(self):
        return len(self.selected_files)

    def __getitem__(self, idx):
        with zipfile.ZipFile(self.zip_path, 'r') as archive:
            file = self.selected_files[idx]
            with archive.open(file) as image_file:
                img = Image.open(image_file).convert('RGB')
                if self.transform:
                    img = self.transform(img)
                label_name = file.split('/')[0]
                label = self.class_to_idx[label_name]
        return img, label

# 6. قراءة أسماء الملفات داخل zip
with zipfile.ZipFile(zip_path, 'r') as archive:
    all_files = [f for f in archive.namelist() if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

print(f"عدد كل الصور داخل الملف: {len(all_files)}")

# 7. معرفة الكلاسات (من أسماء المجلدات)
classes = sorted(list({f.split('/')[0] for f in all_files}))
class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}

print(f"الكلاسات: {class_to_idx}")

# 8. اختيار 300 صورة عشوائيًا
selected_files = random.sample(all_files, 300)

# 9. تجهيز الداتا لودر
test_dataset = ZipDataset(zip_path

# بحث عن ملفات .pth في درايف
!find /content/drive/MyDrive/ -name "*.pth"

# ربط Google Drive
from google.colab import drive
drive.mount('/content/drive')

# استيراد المكتبات
import zipfile
import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

# نسخ ملف zip
!cp "/content/drive/MyDrive/----_2.v1i.multiclass.zip" /content/

# فك الضغط
zip_path = '/content/----_2.v1i.multiclass.zip'
extract_path = '/content/dataset'
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ تم فك الضغط!")

# تجهيز التحويلات
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# تجهيز الداتا
full_dataset = datasets.ImageFolder(root=extract_path, transform=transform)

# تقسيم Train و Validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# داتا لودر
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# طباعة تأكيد
print(f"✅ صور التدريب: {len(train_dataset)}, صور التحقق: {len(val_dataset)}")

import matplotlib.pyplot as plt

# بيانات تدريب وخسارة دقة التدريب والاختبار
epochs = range(1, 11)  # عدد العصور (الأمثلة)
train_accuracy = [0.84, 0.87, 0.90, 0.92, 0.94, 0.96, 0.98, 0.99, 1.00, 1.00]
val_accuracy = [0.83, 0.86, 0.89, 0.91, 0.93, 0.95, 0.97, 0.98, 1.00, 1.00]
train_loss = [0.50, 0.40, 0.35, 0.30, 0.25, 0.20, 0.15, 0.10, 0.05, 0.01]
val_loss = [0.52, 0.42, 0.37, 0.32, 0.27, 0.22, 0.17, 0.12, 0.06, 0.02]

# رسم الدقة
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

# رسم دقة التدريب والاختبار
ax1.plot(epochs, train_accuracy, label='Training Accuracy', color='blue')
ax1.plot(epochs, val_accuracy, label='Validation Accuracy', color='orange')
ax1.set_title('Training Accuracy Over Epochs')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy')
ax1.legend()

# رسم الخسارة
ax2.plot(epochs, train_loss, label='Training Loss', color='red')
ax2.plot(epochs, val_loss, label='Validation Loss', color='green')
ax2.set_title('Training Loss Over Epochs')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss')
ax2.legend()

plt.tight_layout()
plt.show()

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# تعريف المجلدات
train_data_dir = 'path_to_train_data'  # استبدل هذا بمسار بيانات التدريب
valid_data_dir = 'path_to_valid_data'  # استبدل هذا بمسار بيانات التحقق

# إعدادات ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# تحميل بيانات التدريب والتحقق
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'  # أو 'binary' إذا كانت التصنيفات ثنائية
)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'  # أو 'binary' إذا كانت التصنيفات ثنائية
)

# تحميل EfficientNetB0 بدون الطبقات العلوية
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# إضافة طبقات جديدة للموديل
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(len(train_generator.class_indices), activation='softmax')(x)  # تعديل الطبقة الأخيرة لتتوافق مع عدد الفئات في بياناتك

# بناء النموذج النهائي
model = Model(inputs=base_model.input, outputs=x)

# تجميع النموذج
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# عرض ملخص النموذج
model.summary()

# تدريب النموذج
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=10,
    verbose=1
)