# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CVWYygfQkTR6I6tMoGuuSXl8ij9c2sW-
"""

from google.colab import files
uploaded = files.upload()
# Note:  The provided file path is not compatible with the files.upload() function.
# It expects a filename or a list of filenames.  To upload a local file, you would
# typically use files.upload() and then access the uploaded files using the returned dictionary.
# Example: uploaded_file = list(uploaded.keys())[0]

import zipfile
import os

zip_path = "----_2.v1i.multiclass.zip"  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ Ø±ÙØ¹ØªÙ‡
extract_path = "images_dataset"  # Ù…Ø¬Ù„Ø¯ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("ØªÙ… ÙÙƒ Ø§Ù„Ø¶ØºØ· Ø¨Ù†Ø¬Ø§Ø­!")

import matplotlib.pyplot as plt
import os
import cv2
from glob import glob

# Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·
image_paths = glob(os.path.join(extract_path, '*'))

fig, axes = plt.subplots(1, 5, figsize=(15, 5))
for i, img_path in enumerate(image_paths[:5]):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ Ø£Ù„ÙˆØ§Ù† OpenCV Ø¥Ù„Ù‰ RGB
    axes[i].imshow(img)
    axes[i].axis("off")
plt.show()

import matplotlib.pyplot as plt
import os
import cv2
from glob import glob

# Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·
image_paths = glob(os.path.join(extract_path, '*'))

fig, axes = plt.subplots(1, 5, figsize=(15, 5))
for i, img_path in enumerate(image_paths[:5]):
    img = cv2.imread(img_path)

    # Check if image was loaded successfully
    if img is not None:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ Ø£Ù„ÙˆØ§Ù† OpenCV Ø¥Ù„Ù‰ RGB
        axes[i].imshow(img)
        axes[i].axis("off")
    else:
        print(f"Failed to load image: {img_path}")

plt.show()

import matplotlib.pyplot as plt
import os
import cv2
from glob import glob

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„ØµÙˆØ± ÙÙ‚Ø·
image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")

# Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ†ØªÙ‡ÙŠ Ø¨Ø§Ù…ØªØ¯Ø§Ø¯ ØµÙˆØ±Ø© ÙÙ‚Ø·
image_paths = [f for f in glob(os.path.join(extract_path, '*')) if f.lower().endswith(image_extensions)]

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØµÙˆØ±
if len(image_paths) == 0:
    print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ØµÙˆØ± ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
else:
    fig, axes = plt.subplots(1, min(5, len(image_paths)), figsize=(15, 5))  # Ø¹Ø±Ø¶ 5 ØµÙˆØ± ÙÙ‚Ø· Ø£Ùˆ Ø£Ù‚Ù„ Ø­Ø³Ø¨ Ø§Ù„Ù…ØªÙˆÙØ±

    for i, img_path in enumerate(image_paths[:5]):
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ OpenCV Ø¥Ù„Ù‰ RGB
            axes[i].imshow(img)
            axes[i].axis("off")
        else:
            print(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {img_path}")

    plt.show()

import os

extract_path = "images_dataset"  # Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„ØµÙˆØ± ÙÙŠÙ‡
files = os.listdir(extract_path)  # Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¯Ø§Ø®Ù„Ù‡

print("Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·:")
for file in files:
    print(file)

import os
from glob import glob

# Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø­ÙŠØ« ØªÙ… ÙÙƒ Ø§Ù„Ø¶ØºØ·
extract_path = "images_dataset"

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© (train, test, valid)
image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")

# Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©
image_paths = []
for folder in ["train", "valid", "test"]:  # Ø§Ù„Ø¨Ø­Ø« ÙÙ‚Ø· Ø¯Ø§Ø®Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    folder_path = os.path.join(extract_path, folder)
    image_paths.extend(glob(os.path.join(folder_path, "**/*"), recursive=True))  # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª

# ØªØµÙÙŠØ© Ø§Ù„ØµÙˆØ± ÙÙ‚Ø·
image_paths = [f for f in image_paths if f.lower().endswith(image_extensions)]

print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(image_paths)} ØµÙˆØ±Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©.")

import matplotlib.pyplot as plt
import cv2

if len(image_paths) > 0:
    fig, axes = plt.subplots(1, min(5, len(image_paths)), figsize=(15, 5))  # Ø¹Ø±Ø¶ Ø­ØªÙ‰ 5 ØµÙˆØ± ÙÙ‚Ø·
    for i, img_path in enumerate(image_paths[:5]):
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            axes[i].imshow(img)
            axes[i].axis("off")
        else:
            print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
    plt.show()
else:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©.")

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
from tensorflow.keras.applications import MobileNetV2, ResNet50
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.preprocessing import image

# Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
use_mobilenet = True  # True Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… MobileNetV2, False Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ResNet50

if use_mobilenet:
    model = MobileNetV2(weights="imagenet")
    preprocess_input = mobilenet_preprocess
    model_name = "MobileNetV2"
else:
    model = ResNet50(weights="imagenet")
    preprocess_input = resnet_preprocess
    model_name = "ResNet50"

print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ {model_name}")

def predict_image(img_path, model, preprocess_input):
    """ Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØªØ§Ø± """
    img = image.load_img(img_path, target_size=(224, 224))  # Ø¶Ø¨Ø· Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    preds = model.predict(img_array)
    decoded_preds = tf.keras.applications.imagenet_utils.decode_predictions(preds, top=3)[0]

    return decoded_preds

# ØªØ¬Ø±Ø¨Ø© Ø¹Ù„Ù‰ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
sample_img = image_paths[0]
predictions = predict_image(sample_img, model, preprocess_input)

# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
img = cv2.imread(sample_img)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.imshow(img)
plt.axis("off")
plt.title(f"ğŸ“Œ {predictions[0][1]} ({predictions[0][2]*100:.2f}%)")
plt.show()

# Ø·Ø¨Ø§Ø¹Ø© Ø£Ø¹Ù„Ù‰ 3 ØªÙˆÙ‚Ø¹Ø§Øª
for pred in predictions:
    print(f"{pred[1]}: {pred[2]*100:.2f}%")

num_images = 5  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ ØªØµÙ†ÙŠÙÙ‡Ø§
fig, axes = plt.subplots(1, num_images, figsize=(15, 5))

for i, img_path in enumerate(image_paths[:num_images]):
    predictions = predict_image(img_path, model, preprocess_input)
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    axes[i].imshow(img)
    axes[i].axis("off")
    axes[i].set_title(f"{predictions[0][1]} ({predictions[0][2]*100:.2f}%)")

plt.show()

import pandas as pd

results = []

for img_path in image_paths:
    predictions = predict_image(img_path, model, preprocess_input)
    results.append({
        "Image": img_path,
        "Prediction_1": predictions[0][1],
        "Confidence_1": predictions[0][2] * 100,
        "Prediction_2": predictions[1][1],
        "Confidence_2": predictions[1][2] * 100,
        "Prediction_3": predictions[2][1],
        "Confidence_3": predictions[2][2] * 100,
    })

df = pd.DataFrame(results)
df.to_csv("image_classification_results.csv", index=False)

print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù image_classification_results.csv")



import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0, ResNet50
from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
data_dir = "images_dataset"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
img_size = (224, 224)  # Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
batch_size = 32

train_datagen = ImageDataGenerator(
    preprocessing_function=efficientnet_preprocess,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

class_names = list(train_generator.class_indices.keys())
print(f"âœ… Detected Classes: {class_names}")

import os

data_dir = "images_dataset"

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ `images_dataset`
if os.path.exists(data_dir):
    print("âœ… Main directory exists:", os.listdir(data_dir))
    if os.path.exists(os.path.join(data_dir, "train")):
        print("âœ… Train directory exists:", os.listdir(os.path.join(data_dir, "train")))
    else:
        print("âŒ Train directory is missing!")
else:
    print("âŒ Main directory is missing!")

import os

zip_path = "/----_2.v1i.multiclass.zip"  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø®ØªÙ„ÙÙ‹Ø§

if os.path.exists(zip_path):
    print("âœ… The ZIP file exists!")
else:
    print("âŒ The ZIP file does NOT exist. Check the path!")

import zipfile

extract_path = "/extracted_data"  # Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„ÙŠÙ‡

# ÙÙƒ Ø§Ù„Ø¶ØºØ·
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Files extracted successfully to:", extract_path)

import zipfile

zip_path = "/content/----_2.v1i.multiclass.zip"  # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØµØ­ÙŠØ­
extract_path = "/content/extracted_data"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Files extracted successfully to:", extract_path)

import os

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯ Google Colab
files = os.listdir("/content/")
print("ğŸ“‚ Files in /content/:", files)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
zip_path = "/----_2.v1i.multiclass.zip"
if zip_path in files:
    print("âœ… File found:", zip_path)
else:
    print("âŒ File not found! Check the file name or upload it again.")

from google.colab import files

uploaded = files.upload()  # Ø³ØªØ¸Ù‡Ø± Ù†Ø§ÙØ°Ø© Ù„Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ

import os
print("ğŸ“‚ Files in /content/:", os.listdir("/content/"))

import zipfile

zip_path = "/content/----_2.v1i.multiclass.zip"  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØµØ­ÙŠØ­ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
extract_path = "/content/extracted_data"

# ÙÙƒ Ø§Ù„Ø¶ØºØ·
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Files extracted successfully to:", extract_path)

import os

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
print("ğŸ“‚ Extracted files:", os.listdir(extract_path))

dataset_path = "/content/extracted_data/images_dataset"

if os.path.exists(dataset_path):
    print("âœ… Dataset is ready at:", dataset_path)
    print("ğŸ“‚ Folders inside:", os.listdir(dataset_path))
else:
    print("âŒ Dataset folder not found! Check extraction path.")

import os

extract_path = "/content/extracted_data"

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
print("ğŸ“‚ Extracted files and folders:", os.listdir(extract_path))



data_dir = "/content/extracted_data"

import os

print("ğŸ“‚ Available datasets:", os.listdir(data_dir))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±Ø©
img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,  # Ø¥Ø¹Ø§Ø¯Ø© Ù‚ÙŠØ§Ø³ Ø§Ù„Ù‚ÙŠÙ… Ø¨ÙŠÙ† 0 Ùˆ 1
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

# Ø¹Ø±Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
class_names = list(train_generator.class_indices.keys())
print(f"âœ… Detected Classes: {class_names}")

print("ğŸ“‚ Classes inside 'train':", os.listdir(os.path.join(data_dir, "train")))

ğŸ“‚ Classes inside 'train': ['artery', 'vein']

import os

data_dir = "/content/extracted_data"
train_path = os.path.join(data_dir, "train")

print("Classes inside 'train':", os.listdir(train_path))

import tensorflow as tf
import numpy as np
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0, ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
data_dir = "/content/extracted_data"

# Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
img_size = (224, 224)
batch_size = 32

# ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø³ØªÙƒÙˆÙ† Ù„Ù„ØªÙ‚ÙŠÙŠÙ…
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
class_names = list(train_generator.class_indices.keys())
print(f"âœ… Detected Classes: {class_names}")

use_efficientnet = True  # Ø§Ø®ØªØ± True Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… EfficientNetB0 Ø£Ùˆ False Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ResNet50

if use_efficientnet:
    base_model = EfficientNetB0(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
    preprocess_input = tf.keras.applications.efficientnet.preprocess_input
    model_name = "EfficientNetB0"
else:
    base_model = ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
    preprocess_input = tf.keras.applications.resnet50.preprocess_input
    model_name = "ResNet50"

# ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
base_model.trainable = False

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation="relu")(x)
x = Dropout(0.4)(x)  # ØªØ¬Ù†Ø¨ ÙØ±Ø· Ø§Ù„ØªÙƒÙŠÙ (Overfitting)
output_layer = Dense(len(class_names), activation="softmax")(x)  # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ

# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
model = Model(inputs=base_model.input, outputs=output_layer)

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.summary()
print(f"âœ… Model {model_name} is ready!")

import pandas as pd

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙ†Øµ
model_summary = []
model.summary(print_fn=lambda x: model_summary.append(x))

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ ÙˆØ­ÙØ¸Ù‡Ø§
df_summary = pd.DataFrame({"Model Summary": model_summary})
df_summary.to_csv("model_summary.csv", index=False)

print("âœ… Model summary saved as 'model_summary.csv'")

from google.colab import files

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ
files.download("model_summary.csv")

import pandas as pd

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙ†Øµ
model_summary = []
model.summary(print_fn=lambda x: model_summary.append(x))

# Ø­ÙØ¸Ù‡ ÙÙŠ Ù…Ù„Ù Ù†ØµÙŠ Ù…Ù†Ø³Ù‚ Ø¨Ø´ÙƒÙ„ Ø£ÙˆØ¶Ø­
summary_file_path = "model_summary.txt"

with open(summary_file_path, "w") as f:
    for line in model_summary:
        f.write(line + "\n")

print(f"âœ… Model summary saved as '{summary_file_path}'")

from google.colab import files
files.download("model_summary.txt")

# Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
epochs = 10

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=epochs,
    verbose=1
)

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model.save("artery_vein_classifier.h5")
print("âœ… Model Saved Successfully!")

import os

train_path = "/content/extracted_data/train"
valid_path = "/content/extracted_data/valid"

print("ğŸ“‚ Train set contents:", os.listdir(train_path))
print("ğŸ“‚ Validation set contents:", os.listdir(valid_path))

import os

train_path = "/content/extracted_data/train"
valid_path = "/content/extracted_data/valid"
test_path = "/content/extracted_data/test"

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ¦Ø§Øª Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª
for path in [train_path, valid_path, test_path]:
    os.makedirs(os.path.join(path, "artery"), exist_ok=True)
    os.makedirs(os.path.join(path, "vein"), exist_ok=True)

print("âœ… Folders 'artery' and 'vein' have been created inside train, valid, and test.")

import shutil

# Ø¯Ø§Ù„Ø© Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¦Ù‡Ø§
def move_images_to_folders(base_path):
    for filename in os.listdir(base_path):
        file_path = os.path.join(base_path, filename)
        if os.path.isfile(file_path):  # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ Ù…Ù„Ù ØµÙˆØ±Ø©
            if "A" in filename:  # Ø§ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ø´Ø±ÙŠØ§Ù†ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "A" ÙÙŠ Ø§Ù„Ø§Ø³Ù…
                shutil.move(file_path, os.path.join(base_path, "artery", filename))
            elif "V" in filename:  # Ø§ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„ÙˆØ±ÙŠØ¯ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "V" ÙÙŠ Ø§Ù„Ø§Ø³Ù…
                shutil.move(file_path, os.path.join(base_path, "vein", filename))

# Ù†Ù‚Ù„ Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª
for path in [train_path, valid_path, test_path]:
    move_images_to_folders(path)

print("âœ… Images have been moved to their respective folders.")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    valid_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode="categorical",
    subset="validation"
)

print("âœ… Data generators are ready!")

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=10,
    verbose=1
)

print("âœ… Class indices:", train_generator.class_indices)
print("âœ… Number of classes detected:", len(train_generator.class_indices))

# Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø¨Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØ­ÙŠØ­
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation="relu")(x)
x = Dropout(0.4)(x)  # ØªØ¬Ù†Ø¨ ÙØ±Ø· Ø§Ù„ØªÙƒÙŠÙ (Overfitting)
output_layer = Dense(len(train_generator.class_indices), activation="softmax")(x)  # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

# Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = Model(inputs=base_model.input, outputs=output_layer)

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¬Ø¯ÙŠØ¯
model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

print("âœ… Model recompiled with the correct number of classes!")

train_generator.reset()
valid_generator.reset()

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=10,
    verbose=1
)

import pandas as pd

# ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ù„Ù‰ DataFrame
history_df = pd.DataFrame(history.history)

# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù Excel
history_df.to_excel("training_results.xlsx", index=False)

print("âœ… Training results saved as 'training_results.xlsx'")

from google.colab import files
files.download("training_results.xlsx")

import matplotlib.pyplot as plt
import pandas as pd

# ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ù„Ù‰ DataFrame
history_df = pd.DataFrame(history.history)

# ğŸ“Š Ø±Ø³Ù… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
plt.figure(figsize=(10, 5))
plt.plot(history_df['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history_df['val_accuracy'], label='Validation Accuracy', linestyle='dashed', marker='o')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('ğŸ“ˆ Model Training Accuracy Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# ğŸ“‰ Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø© (Loss) Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
plt.figure(figsize=(10, 5))
plt.plot(history_df['loss'], label='Training Loss', marker='o')
plt.plot(history_df['val_loss'], label='Validation Loss', linestyle='dashed', marker='o')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('ğŸ“‰ Model Training Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

import os
import cv2
import random
import numpy as np
import matplotlib.pyplot as plt

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
dataset_path = "/content/extracted_data/test"  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ù€ `train` Ø£Ùˆ `valid` Ù„Ø§Ø®ØªØ¨Ø§Ø± ØµÙˆØ± Ù…Ø®ØªÙ„ÙØ©
categories = ["artery", "vein"]

# Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙƒØ«Ø± Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªØ§Ø­Ø©
    num_images_to_select = min(3, len(images))  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ù‚Ù„ Ù…Ù† 3 ØµÙˆØ±ØŒ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø­ ÙÙ‚Ø·
    selected_images = random.sample(images, num_images_to_select)

    for img in selected_images:
        image_paths.append(os.path.join(category_path, img))

print(f"âœ… Selected {len(image_paths)} images for visualization")

# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ† ÙˆØ§Ù„Ø£ÙˆØ±Ø¯Ø©
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

for i, img_path in enumerate(image_paths):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¥Ù„Ù‰ RGB

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±
    label = "Artery" if "artery" in img_path else "Vein"
    color = (255, 0, 0) if label == "Artery" else (0, 255, 0)  # Ø£Ø­Ù…Ø± Ù„Ù„Ø´Ø±Ø§ÙŠÙŠÙ†ØŒ Ø£Ø®Ø¶Ø± Ù„Ù„Ø£ÙˆØ±Ø¯Ø©

    # Ø±Ø³Ù… Ù…Ø³ØªØ·ÙŠÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø­ÙˆÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© (Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„ÙØ¦Ø© ÙÙ‚Ø·)
    h, w, _ = img.shape
    start_point = (int(w * 0.2), int(h * 0.2))  # Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„Ù…Ø³ØªØ·ÙŠÙ„
    end_point = (int(w * 0.8), int(h * 0.8))  # Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù„Ù…Ø³ØªØ·ÙŠÙ„
    cv2.rectangle(img, start_point, end_point, color, 3)

    # Ø¥Ø¶Ø§ÙØ© Ù†Øµ Ø§Ù„ØªØµÙ†ÙŠÙ
    cv2.putText(img, label, (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
    row, col = i // 3, i % 3
    axes[row, col].imshow(img)
    axes[row, col].axis("off")
    axes[row, col].set_title(f"{label}")

plt.suptitle("Highlighted Arteries and Veins", fontsize=16)
plt.show()

import os

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

for category in categories:
    category_path = os.path.join(dataset_path, category)
    num_images = len(os.listdir(category_path))
    print(f"ğŸ“‚ {category} contains {num_images} images")

import os

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

for category in categories:
    category_path = os.path.join(dataset_path, category)
    num_images = len(os.listdir(category_path))
    print(f"ğŸ“‚ {category} contains {num_images} images")

import os

dataset_path = "/content/extracted_data/test"

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± ÙÙŠ `test/`
all_images = []
for root, dirs, files in os.walk(dataset_path):
    for file in files:
        if file.lower().endswith((".png", ".jpg", ".jpeg")):
            all_images.append(os.path.join(root, file))

print(f"ğŸ“‚ Found {len(all_images)} images in 'test/'")

import shutil

train_vein_path = "/content/extracted_data/train/vein"
test_vein_path = "/content/extracted_data/test/vein"

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ `test/vein/` Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
os.makedirs(test_vein_path, exist_ok=True)

# Ù†Ø³Ø® Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ù† `train/vein/` Ø¥Ù„Ù‰ `test/vein/`
num_images_to_copy = 10  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ù†Ø³Ø®Ù‡Ø§

train_vein_images = os.listdir(train_vein_path)
num_images_to_copy = min(num_images_to_copy, len(train_vein_images))

for img in train_vein_images[:num_images_to_copy]:
    shutil.copy(os.path.join(train_vein_path, img), os.path.join(test_vein_path, img))

print(f"âœ… Copied {num_images_to_copy} vein images from 'train/vein/' to 'test/vein/'")

vein_images = os.listdir("/content/extracted_data/test/vein")
print(f"âœ… Now 'test/vein/' contains {len(vein_images)} images")

import os
import cv2
import random
import numpy as np
import matplotlib.pyplot as plt

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

# Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø­ ÙÙ‚Ø·
    num_images_to_select = min(3, len(images))  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ù‚Ù„ Ù…Ù† 3 ØµÙˆØ±ØŒ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø­ ÙÙ‚Ø·
    selected_images = random.sample(images, num_images_to_select)

    for img in selected_images:
        image_paths.append(os.path.join(category_path, img))

# ğŸ“Œ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙ†Ø§ ØµÙˆØ±Ù‹Ø§ Ù„ÙƒÙ„ ÙØ¦Ø©
print(f"âœ… Selected {len(image_paths)} images for visualization")

# ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
num_images = len(image_paths)
rows = (num_images // 3) + (num_images % 3 > 0)  # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±
fig, axes = plt.subplots(rows, 3, figsize=(15, 10))

# Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ù…ØµÙÙˆÙØ© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø­Ø¯ÙˆØ« Ø®Ø·Ø£ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø£Ù‚Ù„ Ù…Ù† 6
axes = np.array(axes).reshape(-1)

# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ø¹ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ† ÙˆØ§Ù„Ø£ÙˆØ±Ø¯Ø©
for i, img_path in enumerate(image_paths):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¥Ù„Ù‰ RGB

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±
    label = "Artery" if "artery" in img_path else "Vein"
    color = (255, 0, 0) if label == "Artery" else (0, 255, 0)  # Ø£Ø­Ù…Ø± Ù„Ù„Ø´Ø±Ø§ÙŠÙŠÙ†ØŒ Ø£Ø®Ø¶Ø± Ù„Ù„Ø£ÙˆØ±Ø¯Ø©

    # Ø±Ø³Ù… Ù…Ø³ØªØ·ÙŠÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø­ÙˆÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© (Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„ÙØ¦Ø© ÙÙ‚Ø·)
    h, w, _ = img.shape
    start_point = (int(w * 0.2), int(h * 0.2))  # Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„Ù…Ø³ØªØ·ÙŠÙ„
    end_point = (int(w * 0.8), int(h * 0.8))  # Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù„Ù…Ø³ØªØ·ÙŠÙ„
    cv2.rectangle(img, start_point, end_point, color, 3)

    # Ø¥Ø¶Ø§ÙØ© Ù†Øµ Ø§Ù„ØªØµÙ†ÙŠÙ ÙÙˆÙ‚ Ø§Ù„ØµÙˆØ±Ø©
    cv2.putText(img, label, (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
    axes[i].imshow(img)
    axes[i].axis("off")
    axes[i].set_title(f"{label}")

# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø£Ù‚Ù„ Ù…Ù† 6
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.suptitle("Highlighted Arteries and Veins", fontsize=16)
plt.show()

import os

vein_path = "/content/extracted_data/test/vein"
artery_path = "/content/extracted_data/test/artery"

num_vein_images = len(os.listdir(vein_path))
num_artery_images = len(os.listdir(artery_path))

print(f"ğŸ“‚ Artery images: {num_artery_images}")
print(f"ğŸ“‚ Vein images: {num_vein_images}")

import shutil

train_vein_path = "/content/extracted_data/train/vein"
test_vein_path = "/content/extracted_data/test/vein"

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
os.makedirs(test_vein_path, exist_ok=True)

# Ù†Ø³Ø® Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ù† `train/vein/` Ø¥Ù„Ù‰ `test/vein/`
num_images_to_copy = 10  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù†Ø³Ø®Ù‡Ø§
train_vein_images = os.listdir(train_vein_path)
num_images_to_copy = min(num_images_to_copy, len(train_vein_images))

for img in train_vein_images[:num_images_to_copy]:
    shutil.copy(os.path.join(train_vein_path, img), os.path.join(test_vein_path, img))

print(f"âœ… Copied {num_images_to_copy} vein images from 'train/vein/' to 'test/vein/'")

import random

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ± ØªÙØ®ØªØ§Ø± Ù…Ù† ÙƒÙ„ ÙØ¦Ø©
image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    if len(images) > 0:
        num_images_to_select = min(3, len(images))  # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø­ ÙÙ‚Ø·
        selected_images = random.sample(images, num_images_to_select)

        for img in selected_images:
            image_paths.append(os.path.join(category_path, img))

print(f"âœ… Selected {len(image_paths)} images: {image_paths}")

import cv2
import numpy as np
import matplotlib.pyplot as plt

# ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
num_images = len(image_paths)
rows = (num_images // 3) + (num_images % 3 > 0)  # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±
fig, axes = plt.subplots(rows, 3, figsize=(15, 10))

# Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ù…ØµÙÙˆÙØ© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø­Ø¯ÙˆØ« Ø®Ø·Ø£ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø£Ù‚Ù„ Ù…Ù† 6
axes = np.array(axes).reshape(-1)

# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ø¹ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ† ÙˆØ§Ù„Ø£ÙˆØ±Ø¯Ø©
for i, img_path in enumerate(image_paths):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¥Ù„Ù‰ RGB

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±
    label = "Artery" if "artery" in img_path else "Vein"
    color = (255, 0, 0) if label == "Artery" else (0, 255, 0)  # Ø£Ø­Ù…Ø± Ù„Ù„Ø´Ø±Ø§ÙŠÙŠÙ†ØŒ Ø£Ø®Ø¶Ø± Ù„Ù„Ø£ÙˆØ±Ø¯Ø©

    # Ø±Ø³Ù… Ù…Ø³ØªØ·ÙŠÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø­ÙˆÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© (Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„ÙØ¦Ø© ÙÙ‚Ø·)
    h, w, _ = img.shape
    start_point = (int(w * 0.2), int(h * 0.2))  # Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„Ù…Ø³ØªØ·ÙŠÙ„
    end_point = (int(w * 0.8), int(h * 0.8))  # Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù„Ù…Ø³ØªØ·ÙŠÙ„
    cv2.rectangle(img, start_point, end_point, color, 3)

    # Ø¥Ø¶Ø§ÙØ© Ù†Øµ Ø§Ù„ØªØµÙ†ÙŠÙ ÙÙˆÙ‚ Ø§Ù„ØµÙˆØ±Ø©
    cv2.putText(img, label, (start_point[0], start_point[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
    axes[i].imshow(img)
    axes[i].axis("off")
    axes[i].set_title(f"{label}")

# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø£Ù‚Ù„ Ù…Ù† 6
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.suptitle("Highlighted Arteries and Veins", fontsize=16)
plt.show()

import os

vein_path = "/content/extracted_data/test/vein"
artery_path = "/content/extracted_data/test/artery"

vein_images = os.listdir(vein_path)
artery_images = os.listdir(artery_path)

print(f"ğŸ“‚ Artery images: {len(artery_images)}")
print(f"ğŸ“‚ Vein images: {len(vein_images)}")

# Ø¹Ø±Ø¶ Ø£Ø³Ù…Ø§Ø¡ Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± ÙÙŠ vein Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù…Ù„ÙØ§Øª ØµØ­ÙŠØ­Ø©
if vein_images:
    print("ğŸ”¹ Sample Vein Images:", vein_images[:5])  # Ø¹Ø±Ø¶ 5 ØµÙˆØ± Ù…Ù† Ø§Ù„Ø£ÙˆØ±Ø¯Ø©

import os

vein_path = "/content/extracted_data/test/vein"
artery_path = "/content/extracted_data/test/artery"

vein_images = os.listdir(vein_path)
artery_images = os.listdir(artery_path)

print(f"ğŸ“‚ Artery images: {len(artery_images)}")
print(f"ğŸ“‚ Vein images: {len(vein_images)}")

# Ø¹Ø±Ø¶ Ø£Ø³Ù…Ø§Ø¡ Ø¨Ø¹Ø¶ Ø§Ù„ØµÙˆØ± ÙÙŠ vein Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù…Ù„ÙØ§Øª ØµØ­ÙŠØ­Ø©
if vein_images:
    print("ğŸ”¹ Sample Vein Images:", vein_images[:5])  # Ø¹Ø±Ø¶ 5 ØµÙˆØ± Ù…Ù† Ø§Ù„Ø£ÙˆØ±Ø¯Ø©

import random

dataset_path = "/content/extracted_data/test"
categories = ["artery", "vein"]

image_paths = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = os.listdir(category_path)

    if len(images) > 0:
        num_images_to_select = min(3, len(images))  # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ§Ø­ ÙÙ‚Ø·
        selected_images = random.sample(images, num_images_to_select)

        for img in selected_images:
            image_paths.append(os.path.join(category_path, img))

# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡Ø§
print(f"âœ… Selected {len(image_paths)} images:")
for path in image_paths:
    print("ğŸ”¹", path)

# Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
epochs = 10

# Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=epochs,
    verbose=1
)

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model.save("artery_vein_classifier.h5")
print("âœ… Model Saved Successfully!")

# Ensure the following code blocks are run above this cell to define the model:
#  ..
# %%
# use_efficientnet = True  # Ø§Ø®ØªØ± True Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… EfficientNetB0 Ø£Ùˆ False Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ResNet50

# if use_efficientnet:
#     base_model = EfficientNetB0(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
#     preprocess_input = tf.keras.applications.efficientnet.preprocess_input
#     model_name = "EfficientNetB0"
# else:
#     base_model = ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
#     preprocess_input = tf.keras.applications.resnet50.preprocess_input
#     model_name = "ResNet50"

# # ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# base_model.trainable = False

# # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
# x = GlobalAveragePooling2D()(base_model.output)
# x = Dense(256, activation="relu")(x)
# x = Dropout(0.4)(x)  # ØªØ¬Ù†Ø¨ ÙØ±Ø· Ø§Ù„ØªÙƒÙŠÙ (Overfitting)
# output_layer = Dense(len(class_names), activation="softmax")(x)  # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ

# # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
# model = Model(inputs=base_model.input, outputs=output_layer)

# # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# model.summary()
# print(f"âœ… Model {model_name} is ready!")

# # %%
# print("âœ… Class indices:", train_generator.class_indices)
# print("âœ… Number of classes detected:", len(train_generator.class_indices))

# # %%
# # Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø¨Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØ­ÙŠØ­
# x = GlobalAveragePooling2D()(base_model.output)
# x = Dense(256, activation="relu")(x)
# x = Dropout(0.4)(x)  # ØªØ¬Ù†Ø¨ ÙØ±Ø· Ø§Ù„ØªÙƒÙŠÙ (Overfitting)
# output_layer = Dense(len(train_generator.class_indices), activation="softmax")(x)  # Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

# # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# model = Model(inputs=base_model.input, outputs=output_layer)

# # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¬Ø¯ÙŠØ¯
# model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# print("âœ… Model recompiled with the correct number of classes!")

from tensorflow.keras.callbacks import CSVLogger

csv_logger = CSVLogger("training_history.csv")

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=epochs,
    verbose=1,
    callbacks=[csv_logger]  # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
)

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model.save("artery_vein_classifier.h5")
print("âœ… Model Saved Successfully!")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· ÙƒÙ…Ø«Ø§Ù„
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(2,2),
    Flatten

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· ÙƒÙ…Ø«Ø§Ù„
model = Sequential([
    Conv2D(32, (3

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),  # Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙØ§Ù
    MaxPooling2D(pool_size=(2, 2)),  # Ø·Ø¨Ù‚Ø© ØªØ¬Ù…ÙŠØ¹
    Conv2D(64, (3, 3), activation='relu'),  # Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙØ§Ù Ø£Ø®Ø±Ù‰
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø¥Ù„Ù‰ Ø´ÙƒÙ„ Ø®Ø·ÙŠ
    Dense(128, activation='relu'),  # Ø·Ø¨Ù‚Ø© Ù…Ø®ÙÙŠØ©
    Dense(1, activation='sigmoid')  # Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø«Ù†Ø§Ø¦ÙŠ (ÙˆØ±ÙŠØ¯/Ø´Ø±ÙŠØ§Ù†)
])

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("âœ… Model Created Successfully!")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
model = Sequential([
    Input(shape=(128, 128, 3)),  # ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù‡Ù†Ø§
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')  # Ø¥Ø®Ø±Ø§Ø¬ Ø«Ù†Ø§Ø¦ÙŠ (ÙˆØ±ÙŠØ¯/Ø´Ø±ÙŠØ§Ù†)
])

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("âœ… Model Created Successfully Without Warnings!")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ø¬ÙŠÙ… Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ [0,1]
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚
train_generator = train_datagen.flow_from_directory(
    "path_to_train_data",  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary'
)

valid_generator = valid_datagen.flow_from_directory(
    "path_to_valid_data",  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary'
)

print("âœ… Data Generators Ready!")

from google.colab import drive
drive.mount('/content/drive')

# Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_data_path = "/content/drive/MyDrive/dataset/train"
valid_data_path = "/content/drive/MyDrive/dataset/validation"

import os
print(os.listdir("/content/dataset"))  # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯

import os

dataset_path = "/content/dataset"  # Ø¶Ø¹ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ù†Ø§

if os.path.exists(dataset_path):
    print("âœ… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…ÙˆØ¬ÙˆØ¯:", os.listdir(dataset_path))
else:
    print("âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ùƒ Ù‚Ù…Øª Ø¨Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")

from google.colab import drive
drive.mount('/content/drive')

# ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ Ø¯Ø±Ø§ÙŠÙ
!ls "/content/drive/MyDrive/"

from google.colab import files
uploaded = files.upload()

!apt-get install unrar

!unrar x "/content/drive/MyDrive/New folder.rar" "/content/drive/MyDrive/dataset/"

!ls "/content/drive/MyDrive/"

!ls "/content/drive/MyDrive/"

!mv "/content/drive/MyDrive/New folder.rar" "/content/drive/MyDrive/New_folder.rar"

!ls "/content/drive/MyDrive/"

import os

train_path = "/content/drive/MyDrive/dataset/train"  # Ø¶Ø¹ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ù†Ø§

# Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙØ¦Ø§Øª
classes = os.listdir(train_path)

# Ø·Ø¨Ø§Ø¹Ø© Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª ÙˆØ£Ø³Ù…Ø§Ø¦Ù‡Ø§
print(f"ğŸ”¹ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª (Classes): {len(classes)}")
print(f"ğŸ“‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª: {classes}")

from google.colab import files
uploaded = files.upload()

!ls "/content/drive/MyDrive/"

!find "/content/drive/MyDrive/" -name "*.zip"

import zipfile
import os

# Ø­Ø¯Ø¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· ÙˆÙ…Ø³Ø§Ø± ÙÙƒ Ø§Ù„Ø¶ØºØ·
zip_path = "/content/drive/MyDrive/----_2.v1i.multiclass.zip"  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­
extract_path = "/content/drive/MyDrive/dataset"  # Ù…Ø¬Ù„Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·

# ÙÙƒ Ø§Ù„Ø¶ØºØ·
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ:", extract_path)

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!ls "/content/drive/MyDrive/"

!find "/content/drive/" -name "*.zip"

!ls "/content/drive/MyDrive/"

import zipfile
import os

zip_path = "/content/drive/MyDrive/----_2.v1i.multiclass.zip"  # Ø¶Ø¹ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ù†Ø§
extract_path = "/content/drive/MyDrive/dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ:", extract_path)

train_path = "/content/drive/MyDrive/dataset/train"  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨

# Ø¹Ø±Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
classes = os.listdir(train_path)
print(f"ğŸ”¹ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª (Classes): {len(classes)}")
print(f"ğŸ“‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª: {classes}")

import os

train_path = "/content/drive/MyDrive/dataset/train"
subfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]

if len(subfolders) > 0:
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(subfolders)} ÙØ¦Ø§Øª Ø¯Ø§Ø®Ù„ `train/`.")
    print(f"ğŸ“‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª: {subfolders}")
else:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ¦Ø§Øª Ø¯Ø§Ø®Ù„ `train/`. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹ Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ¦Ø§Øª!")

import os
import shutil

train_path = "/content/drive/MyDrive/dataset/train"
organized_path = "/content/drive/MyDrive/dataset/organized_train"

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù†Ø¸Ù…
os.makedirs(organized_path, exist_ok=True)

# ÙØ±Ø² Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø§Ø³Ù… (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ ØªÙ†Ø³ÙŠÙ‚ Ø§Ø³Ù… Ù…Ù„ÙØ§ØªÙƒ)
for filename in os.listdir(train_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„ØµÙˆØ±
        class_name = filename.split("_")[0]  # Ø§ÙØªØ±Ø¶ Ø£Ù† Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù‡Ùˆ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù

        class_folder = os.path.join(organized_path, class_name)
        os.makedirs(class_folder, exist_ok=True)

        shutil.move(os.path.join(train_path, filename), os.path.join(class_folder, filename))

print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ¦Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")

train_data_path = "/content/drive/MyDrive/dataset/organized_train"
valid_data_path = "/content/drive/MyDrive/dataset/organized_validation"  # ØªØ­ØªØ§Ø¬ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØªØ­Ù‚Ù‚

train_generator = train_datagen.flow_from_directory(
    train_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'  # Ù„Ø£Ù† Ù„Ø¯ÙŠÙƒ Ø£ÙƒØ«Ø± Ù…Ù† ÙØ¦Ø©
)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")

import os

validation_path = "/content/drive/MyDrive/dataset/organized_validation"

if os.path.exists(validation_path):
    print(f"âœ… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…ÙˆØ¬ÙˆØ¯: {validation_path}")
    print(f"ğŸ“‚ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª: {os.listdir(validation_path)}")
else:
    print("âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ùƒ Ø£Ù†Ø´Ø£ØªÙ‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.")

import shutil

valid_path = "/content/drive/MyDrive/dataset/validation"
organized_valid_path = "/content/drive/MyDrive/dataset/organized_validation"

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯
os.makedirs(organized_valid_path, exist_ok=True)

# ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ¦Ø§Øª
for filename in os.listdir(valid_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„ØµÙˆØ±
        class_name = filename.split("_")[0]  # Ø§ÙØªØ±Ø¶ Ø£Ù† Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù‡Ùˆ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù

        class_folder = os.path.join(organized_valid_path, class_name)
        os.makedirs(class_folder, exist_ok=True)

        shutil.move(os.path.join(valid_path, filename), os.path.join(class_folder, filename))

print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ `organized_validation` ÙˆØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„Ù‡!")

!find "/content/drive/MyDrive/" -name "validation"

os.makedirs(validation_path, exist_ok=True)
print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ `validation` Ø¨Ù†Ø¬Ø§Ø­!")

import shutil

organized_valid_path = "/content/drive/MyDrive/dataset/organized_validation"

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ù†Ø¸Ù…
os.makedirs(organized_valid_path, exist_ok=True)

# ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ¦Ø§Øª
for class_name in os.listdir(validation_path):
    class_folder = os.path.join(validation_path, class_name)
    if os.path.isdir(class_folder):  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù…Ø¬Ù„Ø¯ ÙˆÙ„ÙŠØ³ Ù…Ù„Ù
        organized_class_folder = os.path.join(organized_valid_path, class_name)
        os.makedirs(organized_class_folder, exist_ok=True)

        for filename in os.listdir(class_folder):
            file_path = os.path.join(class_folder, filename)
            if os.path.isfile(file_path):  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù…Ù„Ù ØµÙˆØ±Ø©
                shutil.move(file_path, os.path.join(organized_class_folder, filename))

print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­!")

train_data_path = "/content/drive/MyDrive/dataset/organized_train"
valid_data_path = "/content/drive/MyDrive/dataset/organized_validation"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'  # Ù„Ø£Ù† Ù„Ø¯ÙŠÙƒ Ø£ÙƒØ«Ø± Ù…Ù† ÙØ¦Ø©
)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­!")

import os

valid_data_path = "/content/drive/MyDrive/dataset/organized_validation"

if os.path.exists(valid_data_path):
    print(f"âœ… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…ÙˆØ¬ÙˆØ¯: {valid_data_path}")
    print(f"ğŸ“‚ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª: {os.listdir(valid_data_path)}")
else:
    print("âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ `organized_validation` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ†Ø¸ÙŠÙ…Ù‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.")

import os

validation_original_path = "/content/drive/MyDrive/dataset/validation"

if os.path.exists(validation_original_path):
    images = [f for f in os.listdir(validation_original_path) if f.endswith((".jpg", ".png"))]
    print(f"ğŸ“· Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ `validation`: {len(images)}")
else:
    print("âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ `validation` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ùƒ Ø£Ù†Ø´Ø£ØªÙ‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.")

!find "/content/drive/MyDrive/" -type d -name "validation"

import os

validation_path = "/content/drive/MyDrive/dataset/validation"
os.makedirs(validation_path, exist_ok=True)

print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ `validation`: {validation_path}")

import shutil
import random

train_path = "/content/drive/MyDrive/dataset/organized_train"
validation_path = "/content/drive/MyDrive/dataset/validation"

os.makedirs(validation_path, exist_ok=True)

# Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ù†Ù‚Ù„Ù‡Ø§ Ù„ÙƒÙ„ ÙØ¦Ø©
num_images_to_move = 20

for class_name in os.listdir(train_path):
    class_train_folder = os.path.join(train_path, class_name)
    class_valid_folder = os.path.join(validation_path, class_name)

    if os.path.isdir(class_train_folder):  # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ù‡Ùˆ Ù…Ø¬Ù„Ø¯ ÙØ¦Ø© ÙˆÙ„ÙŠØ³ Ù…Ù„Ù
        os.makedirs(class_valid_folder, exist_ok=True)

        # Ø§Ø®ØªØ± ØµÙˆØ±Ù‹Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ Ù„Ù†Ù‚Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚
        images = [f for f in os.listdir(class_train_folder) if f.endswith((".jpg", ".png"))]
        images_to_move = random.sample(images, min(num_images_to_move, len(images)))

        for image in images_to_move:
            shutil.move(os.path.join(class_train_folder, image), os.path.join(class_valid_folder, image))

print("âœ… ØªÙ… Ù†Ù‚Ù„ ØµÙˆØ± Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­!")

valid_generator = valid_datagen.flow_from_directory(
    validation_path,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­!")

import os

train_data_path = "/content/drive/MyDrive/dataset/organized_train"

if os.path.exists(train_data_path):
    train_classes = os.listdir(train_data_path)
    print(f"ğŸ“‚ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {len(train_classes)}")
    print(f"ğŸ“‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª: {train_classes[:20]}")  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 20 ÙØ¦Ø© ÙÙ‚Ø·
else:
    print("âŒ Ù…Ø³Ø§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")

keywords = ["artery", "vein", "blood", "vessel"]  # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
matching_classes = [cls for cls in train_classes if any(keyword in cls.lower() for keyword in keywords)]

print(f"ğŸ” Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø£ÙˆØ±Ø¯Ø© ÙˆØ§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†: {matching_classes}")

for i, cls in enumerate(train_classes[:50]):  # Ø¹Ø±Ø¶ 50 ÙØ¦Ø© ÙÙ‚Ø·
    print(f"{i+1}. {cls}")

pip install tensorflow

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

# ØªØ­Ù…ÙŠÙ„ EfficientNetB0 Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¹Ù„ÙŠØ§
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Ø¥Ø¶Ø§ÙØ© Ø·Ø¨Ù‚Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¹Ù„ÙˆÙŠØ©
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(2, activation='softmax')(x)  # ÙØ¦ØªÙŠÙ†: Ø³Ù„ÙŠÙ… Ø£Ùˆ Ù…Ø±ÙŠØ¶

# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
model = Model(inputs=base_model.input, outputs=x)

# ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§)
base_model.trainable = False

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Adam ÙƒÙ…Ø­Ø³Ù†
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.summary()

# Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§Ø³ØªØ®Ø¯Ø§Ù… ImageDataGenerator)
train_datagen = ImageDataGenerator(
    rescale=1./255,  # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ±
    rotation_range=40,  # ØªØ¯ÙˆÙŠØ± Ø§Ù„ØµÙˆØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§
    width_shift_range=0.2,  # ØªØ­Ø±ÙŠÙƒ Ø§Ù„ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠØ§
    height_shift_range=0.2,  # ØªØ­Ø±ÙŠÙƒ Ø§Ù„ØµÙˆØ±Ø© Ø±Ø£Ø³ÙŠØ§
    shear_range=0.2,  # Ø§Ù„ØªÙˆØ§Ø¡ Ø§Ù„ØµÙˆØ±
    zoom_range=0.2,  # ØªÙƒØ¨ÙŠØ± Ø§Ù„ØµÙˆØ±
    horizontal_flip=True,  # Ø¹ÙƒØ³ Ø§Ù„ØµÙˆØ± Ø£ÙÙ‚ÙŠÙ‹Ø§
    fill_mode='nearest')  # Ù…Ù„Ø¡ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª (Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙˆØ«ÙŠÙ‚)
train_generator = train_datagen.flow_from_directory(
    'path/to/train_data',  # Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
    target_size=(224, 224),  # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    batch_size=32,
    class_mode='categorical')  # Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ (Ø³Ù„ÙŠÙ… / Ù…Ø±ÙŠØ¶)

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model.save('aortic_valve_classifier.h5')

import os
print(os.listdir('https://colab.research.google.com/drive/1CVWYygfQkTR6I6tMoGuuSXl8ij9c2sW-#'))

import os

# ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±
data_dir = 'path/to/train_data'
print(os.listdir(data_dir))  # ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø«Ù„ 'Ø³Ù„ÙŠÙ…' Ùˆ 'Ù…Ø±ÙŠØ¶'

/path/to/train_data/
    Ø³Ù„ÙŠÙ…/
        image1.jpg
        image2.jpg
    Ù…Ø±ÙŠØ¶/
        image1.jpg
        image2.jpg

from google.colab import drive
drive.mount('/content/drive')

zip_file_path = '/content/drive/My Drive/----_2.v1i.multiclass.zip'

import zipfile
import os

# Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ·
zip_file_path = '/content/drive/My Drive/----_2.v1i.multiclass.zip'
extract_folder = '/content/drive/My Drive/extracted_dataset/'

# ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
extracted_files = os.listdir(extract_folder)
print(extracted_files)

import zipfile
import os

# Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ·
zip_file_path = '/content/drive/My Drive/----_2.v1i.multiclass.zip'
extract_folder = '/content/drive/My Drive/extracted_dataset/'

# ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
extracted_files = os.listdir(extract_folder)
print(extracted_files)

extracted_files = os.listdir(extract_folder)
print(extracted_files)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_datagen = ImageDataGenerator(rescale=1./255)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
train_generator = train_datagen.flow_from_directory(
    extract_folder,  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø°ÙŠ ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠÙ‡
    target_size=(224, 224),  # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    batch_size=32,
    class_mode='categorical')  # Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ (Ø³Ù„ÙŠÙ… / Ù…Ø±ÙŠØ¶)

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

# ØªØ­Ù…ÙŠÙ„ EfficientNetB0 Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¹Ù„ÙŠØ§
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Ø¥Ø¶Ø§ÙØ© Ø·Ø¨Ù‚Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¹Ù„ÙˆÙŠØ©
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(3, activation='softmax')(x)  # 3 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ…ØŒ Ù…Ø±ÙŠØ¶ØŒ ÙˆØ§Ù„ÙØ¦Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©

# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
model = Model(inputs=base_model.input, outputs=x)

# ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§)
base_model.trainable = False

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Adam ÙƒÙ…Ø­Ø³Ù†
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.summary()

# Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§Ø³ØªØ®Ø¯Ø§Ù… ImageDataGenerator)
train_datagen = ImageDataGenerator(
    rescale=1./255,  # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ±
    rotation_range=40,  # ØªØ¯ÙˆÙŠØ± Ø§Ù„ØµÙˆØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§
    width_shift_range=0.2,  # ØªØ­Ø±ÙŠÙƒ Ø§Ù„ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠØ§
    height_shift_range=0.2,  # ØªØ­Ø±ÙŠÙƒ Ø§Ù„ØµÙˆØ±Ø© Ø±Ø£Ø³ÙŠØ§
    shear_range=0.2,  # Ø§Ù„ØªÙˆØ§Ø¡ Ø§Ù„ØµÙˆØ±
    zoom_range=0.2,  # ØªÙƒØ¨ÙŠØ± Ø§Ù„ØµÙˆØ±
    horizontal_flip=True,  # Ø¹ÙƒØ³ Ø§Ù„ØµÙˆØ± Ø£ÙÙ‚ÙŠÙ‹Ø§
    fill_mode='nearest')  # Ù…Ù„Ø¡ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª (Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙˆØ«ÙŠÙ‚)
train_generator = train_datagen.flow_from_directory(
    'path/to/train_data',  # Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
    target_size=(224, 224),  # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    batch_size=32,
    class_mode='categorical')  # Ø§Ù„ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª (3 ÙØ¦Ø§Øª)

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model.save('aortic_valve_classifier.h5')

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/My Drive/train_data'  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

import os

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±
data_dir = '/content/drive/My Drive/train_data'

# Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª
print(os.listdir(data_dir))  # Ø³ÙŠØ¹Ø±Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ù…Ø«Ù„ "Ø³Ù„ÙŠÙ…" Ùˆ "Ù…Ø±ÙŠØ¶"

import os

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
data_dir = '/content/drive/My Drive/datasets/train_data'  # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯
print(os.listdir(data_dir))

file_id = '1pBBXYewdLl6x3Jr7HVQvISM9eVmmSFPW'  # Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù„Ù
download_url = f'https://drive.google.com/uc?id={file_id}'

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
import urllib.request
urllib.request.urlretrieve(download_url, '/content/filename.zip')

import zipfile

with zipfile.ZipFile('/content/filename.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/My Drive/extracted_data')

import urllib.request

file_id = '1pBBXYewdLl6x3Jr7HVQvISM9eVmmSFPW'  # Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù„Ù
download_url = f'https://drive.google.com/uc?id={file_id}'

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ø¬Ø¯Ø¯Ù‹Ø§
urllib.request.urlretrieve(download_url, '/content/filename.zip')

import os
file_path = '/content/filename.zip'
print(f"File size: {os.path.getsize(file_path)} bytes")

import shutil

try:
    shutil.unpack_archive('/content/filename.zip', '/content/drive/My Drive/extracted_data')
    print("File extracted successfully.")
except Exception as e:
    print(f"Error: {e}")

import zipfile

# Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù
zip_file_path = '/content/drive/MyDrive/----_2.v1i.multiclass.zip'
extract_folder = '/content/drive/MyDrive/extracted_data/'  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠÙ‡

# ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

print(f"File extracted to {extract_folder}")

import os

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
extracted_files = os.listdir(extract_folder)
print(extracted_files)  # Ø³ÙŠØ¹Ø±Ø¶ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_datagen = ImageDataGenerator(rescale=1./255)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
train_generator = train_datagen.flow_from_directory(
    extract_folder,  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø°ÙŠ ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠÙ‡
    target_size=(224, 224),  # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    batch_size=32,
    class_mode='categorical')  # Ø§Ù„ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª (Ø³Ù„ÙŠÙ… / Ù…Ø±ÙŠØ¶)

history = model.fit(train_generator, epochs=10, steps_per_epoch=100)

import pandas as pd
import matplotlib.pyplot as plt

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªÙˆÙÙŠØ±Ù‡Ø§
epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
accuracy = [0.8697, 0.8822, 0.8772, 0.8742, 0.8644, 0.8802, 0.8846, 0.8720, 0.8878, 0.8740]
loss = [0.5428, 0.4454, 0.4516, 0.4637, 0.4881, 0.4439, 0.4386, 0.4663, 0.4227, 0.4674]

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Accuracy': accuracy,
    'Loss': loss
})

import ace_tools as tools; tools.display_dataframe_to_user(name="Model Training Results", dataframe=results_df)

# Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬
fig, ax1 = plt.subplots()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy', color='tab:blue')
ax1.plot(epochs, accuracy, color='tab:blue', label='Accuracy')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø«Ø§Ù†ÙŠ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø®Ø³Ø§Ø±Ø©
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='tab:red')
ax2.plot(epochs, loss, color='tab:red', label='Loss')
ax2.tick_params(axis='y', labelcolor='tab:red')

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
fig.tight_layout()
plt.title("Model Training: Accuracy and Loss Over Epochs")
plt.show()

import pandas as pd

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªÙˆÙÙŠØ±Ù‡Ø§
epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
accuracy = [0.8697, 0.8822, 0.8772, 0.8742, 0.8644, 0.8802, 0.8846, 0.8720, 0.8878, 0.8740]
loss = [0.5428, 0.4454, 0.4516, 0.4637, 0.4881, 0.4439, 0.4386, 0.4663, 0.4227, 0.4674]

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Accuracy': accuracy,
    'Loss': loss
})

# Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
results_df

# Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ù…Ù„Ù CSV ÙÙŠ Ù…Ø¬Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨
file_path = '/mnt/data/training_results.csv'
results_df.to_csv(file_path, index=False)

# ØªÙˆÙÙŠØ± Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
from google.colab import files
files.download(file_path)

# Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ù…Ù„Ù CSV ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
file_path = '/content/training_results.csv'
results_df.to_csv(file_path, index=False)

# ØªÙˆÙÙŠØ± Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
from google.colab import files
files.download(file_path)

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
import matplotlib.pyplot as plt

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
fig, ax1 = plt.subplots()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy', color='tab:blue')
ax1.plot(epochs, accuracy, color='tab:blue', label='Accuracy')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø«Ø§Ù†ÙŠ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø®Ø³Ø§Ø±Ø©
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='tab:red')
ax2.plot(epochs, loss, color='tab:red', label='Loss')
ax2.tick_params(axis='y', labelcolor='tab:red')

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
fig.tight_layout()
plt.title("Model Training: Accuracy and Loss Over Epochs")

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
image_path = '/mnt/data/training_accuracy_loss_plot.png'
plt.savefig(image_path)

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
plt.show()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
from google.colab import files
files.download(image_path)

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
import matplotlib.pyplot as plt

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
fig, ax1 = plt.subplots()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy', color='tab:blue')
ax1.plot(epochs, accuracy, color='tab:blue', label='Accuracy')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø«Ø§Ù†ÙŠ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø®Ø³Ø§Ø±Ø©
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='tab:red')
ax2.plot(epochs, loss, color='tab:red', label='Loss')
ax2.tick_params(axis='y', labelcolor='tab:red')

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
fig.tight_layout()
plt.title("Model Training: Accuracy and Loss Over Epochs")

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± `/content`
image_path = '/content/training_accuracy_loss_plot.png'
plt.savefig(image_path)

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
plt.show()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
from google.colab import files
files.download(image_path)

!pip install tensorflow
!pip install transformers

import tensorflow as tf
from transformers import ViTFeatureExtractor, ViTForImageClassification
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

train_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/train_data',  # Make sure this is the correct path to your dataset
    target_size=(224, 224),  # ViT typically uses 224x224 input size
    batch_size=32,
    class_mode='categorical'
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_datagen = ImageDataGenerator(rescale=1./255)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
train_generator = train_datagen.flow_from_directory(
    extract_folder,  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø°ÙŠ ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠÙ‡
    target_size=(224, 224),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ViT
    batch_size=32,
    class_mode='categorical'  # Ø§Ù„ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª
)

from transformers import ViTFeatureExtractor, ViTForImageClassification
import tensorflow as tf

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ViT
model_name = 'google/vit-base-patch16-224-in21k'  # Ù†Ù…ÙˆØ°Ø¬ ViT Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ ImageNet21k
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

import torch
from transformers import ViTForImageClassification, ViTFeatureExtractor
from torch.utils.data import DataLoader
from torch.optim import Adam
from torchvision import datasets, transforms

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ViT Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Hugging Face
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª

# ØªØ­Ù…ÙŠÙ„ ViT feature extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

# ØªÙ‡ÙŠØ¦Ø© ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØ± Ù„ØªÙ†Ø§Ø³Ø¨ ViT (ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam ÙƒÙ…Ø­Ø³Ù†
optimizer = Adam(model.parameters(), lr=1e-5)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropy Loss
loss_fn = torch.nn.CrossEntropyLoss()

# ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒÙˆØ¯ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss

# Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels Ù‡ÙŠ Ø£Ø±Ù‚Ø§Ù… ØµØ­ÙŠØ­Ø© ÙˆÙ„ÙŠØ³Øª one-hot
for images, labels in train_loader:
    optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
    outputs = model(images)
    logits = outputs.logits

    # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels Ù‡ÙŠ Ø£Ø±Ù‚Ø§Ù… ØµØ­ÙŠØ­Ø© ØªÙ…Ø«Ù„ Ø§Ù„ÙØ¦Ø§Øª
    labels = labels.squeeze()  # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø¨Ø¹Ø¯ ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙˆØ¬Ø¯ (Ù…Ø«Ù„ [batch_size, 1])

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
    loss = loss_fn(logits, labels)  # logits Ù‡ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (batch_size, num_classes)
    loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

    optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
    _, predicted = torch.max(logits, 1)
    correct_preds += (predicted == labels).sum().item()
    total_preds += labels.size(0)

    running_loss += loss.item()

for images, labels in train_loader:
    optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

    # Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
    outputs = model(images)
    logits = outputs.logits

    # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels Ù‡ÙŠ Ø£Ø±Ù‚Ø§Ù… ØµØ­ÙŠØ­Ø© ØªÙ…Ø«Ù„ Ø§Ù„ÙØ¦Ø§Øª
    labels = torch.clamp(labels, min=0, max=1)  # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© (0, 1)

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
    loss = loss_fn(logits, labels)  # logits Ù‡ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (batch_size, num_classes)
    loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

    optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
    _, predicted = torch.max(logits, 1)
    correct_preds += (predicted == labels).sum().item()
    total_preds += labels.size(0)

    running_loss += loss.item()

from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print(f"Number of batches: {len(train_loader)}")

for images, labels in train_loader:
    optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

    # Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
    outputs = model(images)
    logits = outputs.logits

    # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels Ù‡ÙŠ Ø£Ø±Ù‚Ø§Ù… ØµØ­ÙŠØ­Ø© ØªÙ…Ø«Ù„ Ø§Ù„ÙØ¦Ø§Øª
    labels = torch.clamp(labels, min=0, max=1)  # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© (0, 1)

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
    loss = loss_fn(logits, labels)  # logits Ù‡ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (batch_size, num_classes)
    loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

    optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
    _, predicted = torch.max(logits, 1)
    correct_preds += (predicted == labels).sum().item()
    total_preds += labels.size(0)

    running_loss += loss.item()

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epoch_accuracy = correct_preds / total_preds
print(f"Epoch Accuracy: {epoch_accuracy:.4f}")

import torch.optim as optim

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ViT
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# ØªØ­Ù…ÙŠÙ„ ViT Feature Extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

from transformers import ViTForImageClassification, ViTFeatureExtractor

from transformers import ViTForImageClassification, ViTFeatureExtractor
import torch

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ViT
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# ØªØ­Ù…ÙŠÙ„ ViT Feature Extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

from transformers import ViTForImageClassification, ViTFeatureExtractor
import torch

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ViT
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# ØªØ­Ù…ÙŠÙ„ ViT Feature Extractor
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)

from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision import datasets

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„ØªÙ†Ø§Ø³Ø¨ ViT (ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹)
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print(f"Number of batches: {len(train_loader)}")

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:
epoch_loss = running_loss / len(train_loader)
epoch_accuracy = correct_preds / total_preds

print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø©
running_loss = 0.0
correct_preds = 0
total_preds = 0

for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)
        logits = outputs.logits

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(logits, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# ØªØ¹Ø±ÙŠÙ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ epochs
epochs = 10  # Ø¹Ø¯Ø¯ Ø§Ù„Ù€ epochs Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø®Ù„Ø§Ù„Ù‡Ø§

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø©
running_loss = 0.0
correct_preds = 0
total_preds = 0

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)
        logits = outputs.logits

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(logits, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch.optim as optim

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

import torch.optim as optim

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10  # Ø¹Ø¯Ø¯ Ø§Ù„Ù€ epochs
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)
        logits = outputs.logits

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(logits, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn

# ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ epochs
epochs = 10

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)
        logits = outputs.logits

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(logits, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙÙŠ `labels`
print(f"Unique labels: {torch.unique(labels)}")

labels = torch.clamp(labels, min=0, max=1)  # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn

# ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ epochs
epochs = 10

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels ØªØ­ØªÙˆÙŠ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1
        labels = torch.clamp(labels, min=0, max=1)  # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)
        logits = outputs.logits

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(logits, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

#

import torch
import torch.optim as optim
from transformers import ViTForImageClassification
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model_name = 'google/vit-base-patch16-224-in21k'
model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… ÙˆÙ…Ø±ÙŠØ¶

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)
        logits = outputs.logits

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(logits, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(logits, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision import datasets
import torch.nn as nn

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print(f"Number of batches: {len(train_loader)}")

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ResNet18 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.resnet18(pretrained=True)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

import torch
import torch.optim as optim
from torchvision import models
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ResNet18 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.resnet18(pretrained=True)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1 ÙÙ‚Ø·
        labels = torch.clamp(labels, min=0, max=1)

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(outputs, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† PyTorch ÙŠØ³ØªØ®Ø¯Ù… GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ù‹Ø§
model.to(device)

# Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù€ labels) Ø¥Ù„Ù‰ GPU Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
for images, labels in train_loader:
    images, labels = images.to(device), labels.to(device)

    optimizer.zero_grad()

    outputs = model(images)
    loss = loss_fn(outputs, labels)
    loss.backward()

    optimizer.step()

import torch
import torch.optim as optim
from torchvision import models
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ResNet18 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.resnet18(pretrained=True)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels ØªØ­ØªÙˆÙŠ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1
        labels = torch.clamp(labels, min=0, max=1)  # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(outputs, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import pandas as pd
import matplotlib.pyplot as plt
import os

# Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas
df

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
fig, ax1 = plt.subplots()

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss', color='tab:red')
ax1.plot(df['Epoch'], df['Loss'], color='tab:red', label='Loss')
ax1.tick_params(axis='y', labelcolor='tab:red')

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
ax2 = ax1.twinx()  # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ÙˆØ± Y Ù…Ø²Ø¯ÙˆØ¬
ax2.set_ylabel('Accuracy', color='tab:blue')
ax2.plot(df['Epoch'], df['Accuracy'], color='tab:blue', label='Accuracy')
ax2.tick_params(axis='y', labelcolor='tab:blue')

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
fig.tight_layout()
plt.title('Loss and Accuracy over Epochs')
plt.show()

# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
output_dir = '/mnt/data'
os.makedirs(output_dir, exist_ok=True)

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
image_path = os.path.join(output_dir, 'training_loss_accuracy_plot.png')
fig.savefig(image_path)

# ØªÙˆÙÙŠØ± Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image_path

import pandas as pd
import matplotlib.pyplot as plt
import os

# Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas
df

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
fig, ax1 = plt.subplots()

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss', color='tab:red')
ax1.plot(df['Epoch'], df['Loss'], color='tab:red', label='Loss')
ax1.tick_params(axis='y', labelcolor='tab:red')

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
ax2 = ax1.twinx()  # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ÙˆØ± Y Ù…Ø²Ø¯ÙˆØ¬
ax2.set_ylabel('Accuracy', color='tab:blue')
ax2.plot(df['Epoch'], df['Accuracy'], color='tab:blue', label='Accuracy')
ax2.tick_params(axis='y', labelcolor='tab:blue')

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
fig.tight_layout()
plt.title('Loss and Accuracy over Epochs')
plt.show()

# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
output_dir = '/mnt/data'
os.makedirs(output_dir, exist_ok=True)

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
image_path = os.path.join(output_dir, 'training_loss_accuracy_plot.png')
fig.savefig(image_path)

# Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image_path

import pandas as pd

# Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas ÙÙŠ Google Colab
df

"""# New Section"""

import pandas as pd

# Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ù…Ù„Ù CSV
df.to_csv('/mnt/data/training_results.csv', index=False)

# ØªÙˆÙÙŠØ± Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
print("Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: /mnt/data/training_results.csv")

import os

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
files = os.listdir('/content/')
print(files)

import pandas as pd

# Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ù…Ù„Ù CSV Ø¯Ø§Ø®Ù„ Google Colab
df.to_csv('/mnt/data/training_results.csv', index=False)

# Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„
print("Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù:", '/mnt/data/training_results.csv')

import pandas as pd
from google.colab import files

# Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
epochs = 10
loss_values = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracy_values = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0000, 1.0000]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame
data = {
    'Epoch': [i+1 for i in range(epochs)],
    'Loss': loss_values,
    'Accuracy': accuracy_values
}
df = pd.DataFrame(data)

# Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ù…Ù„Ù CSV Ø¯Ø§Ø®Ù„ Google Colab
file_path = '/mnt/data/training_results.csv'
df.to_csv(file_path, index=False)

# Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
print("Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù:", file_path)

# ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Colab
files.download(file_path)

import torch
import torch.optim as optim
from torchvision import models
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.models import DenseNet121_Weights

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§ ÙÙŠ Colab
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ DenseNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ DenseNet121 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
weights = DenseNet121_Weights.IMAGENET1K_V1
model = models.densenet121(weights=weights)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
model.classifier = nn.Linear(model.classifier.in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø£Ùˆ CPU)
model.to(device)

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        # Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø²
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels ØªØ­ØªÙˆÙŠ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1
        labels = torch.clamp(labels, min=0, max=1)  # ØªÙ‚Ù„ÙŠÙ… `labels` Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… 0 Ùˆ 1

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(outputs, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import matplotlib.pyplot as plt

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ù€ epochs
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
epochs = range(1, 11)

plt.figure(figsize=(12, 5))

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, label='Loss', color='red')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, label='Accuracy', color='blue')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
plt.savefig('training_plots.png')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# Ø­ÙØ¸ DataFrame ÙÙŠ Ù…Ù„Ù Excel
results_df.to_excel('training_results.xlsx', index=False)

# Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
plt.figure(figsize=(12, 5))

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, label='Loss', color='red')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, label='Accuracy', color='blue')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
plt.savefig('training_plots.png')
plt.show()

import pandas as pd

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# Ø­ÙØ¸ DataFrame ÙÙŠ Ù…Ù„Ù Excel
results_df.to_excel('training_results.xlsx', index=False)

print("Results have been saved to 'training_results.xlsx'")

import pandas as pd
from google.colab import files

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
losses = [0.5043, 0.2676, 0.1837, 0.1462, 0.1188, 0.0978, 0.0818, 0.0639, 0.0517, 0.0400]
accuracies = [0.8421, 0.9582, 0.9586, 0.9589, 0.9619, 0.9712, 0.9786, 0.9878, 0.9933, 0.9956]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# Ø­ÙØ¸ DataFrame ÙÙŠ Ù…Ù„Ù Excel
results_df.to_excel('training_results.xlsx', index=False)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù ÙƒÙ„ÙŠØ¨ ÙÙŠ Colab
files.download('training_results.xlsx')

import matplotlib.pyplot as plt

# Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
accuracies = [0.8697, 0.8822, 0.8772, 0.8742, 0.8644, 0.8802, 0.8846, 0.872, 0.8878, 0.874]
losses = [0.5428, 0.4454, 0.4516, 0.4637, 0.4881, 0.4439, 0.4386, 0.4663, 0.4227, 0.4674]

plt.figure(figsize=(12, 5))

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
plt.subplot(1, 2, 1)
plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
plt.subplot(1, 2, 2)
plt.plot(epochs, losses, marker='o', color='red', label='Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
plt.tight_layout()
plt.savefig('training_results.png')
plt.show()

import matplotlib.pyplot as plt

# Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
losses = [0.4511, 0.2126, 0.1438, 0.1162, 0.0926, 0.0686, 0.0472, 0.0337, 0.0255, 0.0201]
accuracies = [0.8872, 0.9586, 0.9589, 0.9612, 0.9678, 0.9822, 0.9956, 0.9993, 1.0, 1.0]

plt.figure(figsize=(12, 5))

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, marker='o', color='red', label='Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
plt.tight_layout()
plt.savefig('training_results_v2.png')
plt.show()

pip install timm

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Xception
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù€ Batch Size
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # ØªÙ‚Ù„ÙŠÙ„ batch size

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Xception Ø§Ù„Ù…Ø¹Ø¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = timm.create_model('xception', pretrained=True)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
in_features = model.get_classifier().in_features
model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø£Ùˆ CPU)
model.to(device)

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(outputs, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

# ... (your code)

accumulation_steps = 2  # Accumulate gradients over 2 batches

for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0
    optimizer.zero_grad()

    model.train()
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss = loss / accumulation_steps  # Scale loss to account for accumulation
        loss.backward()

        if (i + 1) % accumulation_steps == 0:
            optimizer.step()
            optimizer.zero_grad()

        # ... (rest of your code)

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm
import gc  # Ù…ÙƒØªØ¨Ø© Ù„Ù„ØªØ­ÙƒÙ… Ø¨Ø§Ù„Ø°Ø§ÙƒØ±Ø©

def train_model():
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
    transform = transforms.Compose([
        transforms.Resize((299, 299)),  # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Xception
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
    ])

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø¹ ØªÙ‚Ù„ÙŠÙ„ batch size
    train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # ØªÙ‚Ù„ÙŠÙ„ batch size

    # ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Xception Ø§Ù„Ù…Ø¹Ø¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§
    model = timm.create_model('xception', pretrained=True)

    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
    in_features = model.get_classifier().in_features
    model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

    # Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø£Ùˆ CPU)
    model.to(device)

    # ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
    optimizer = optim.Adam(model.parameters(), lr=1e-5)

    # ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
    loss_fn = nn.CrossEntropyLoss()

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    epochs = 10
    for epoch in range(epochs):
        running_loss = 0.0
        correct_preds = 0
        total_preds = 0

        model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

            try:
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
                outputs = model(images)

                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
                loss = loss_fn(outputs, labels)
                loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

                optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
                _, predicted = torch.max(outputs, 1)
                correct_preds += (predicted == labels).sum().item()
                total_preds += labels.size(0)

                running_loss += loss.item()

            except RuntimeError as e:
                torch.cuda.empty_cache()
                gc.collect()  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯ÙˆÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                print(f"Skipped batch due to insufficient memory: {e}")

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
        epoch_loss = running_loss / len(train_loader)
        epoch_accuracy = correct_preds / total_preds

        print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

train_model()

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

# ... (your existing code)

# Install PyTorch with CUDA support if not already installed
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Enable mixed precision training
scaler = torch.cuda.amp.GradScaler()

# Training loop with gradient accumulation and mixed precision
accumulation_steps = 2
for epoch in range(epochs):
    # ... (your existing code)

    model.train()
    for i, (images, labels) in enumerate(train_loader):
        # Check and correct label values before moving to device
        labels = labels.clamp(0, 1)  # Ensure labels are within [0, 1]

        images, labels = images.to(device), labels.to(device)

        with torch.autocast(device_type="cuda", dtype=torch.float16):  # Mixed precision
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            loss = loss / accumulation_steps

        scaler.scale(loss).backward()  # Scale loss before backpropagation

        if (i + 1) % accumulation_steps == 0:
            scaler.step(optimizer)  # Update weights
            scaler.update()  # Update scaler
            optimizer.zero_grad()

        # ... (rest of your code)

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

# ... (your existing code)

# Install PyTorch with CUDA support if not already installed
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Enable mixed precision training
scaler = torch.cuda.amp.GradScaler()

# Training loop with gradient accumulation and mixed precision
accumulation_steps = 2
for epoch in range(epochs):
    # ... (your existing code)

    model.train()
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        with torch.autocast(device_type="cuda", dtype=torch.float16):  # Mixed precision
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            loss = loss / accumulation_steps

        scaler.scale(loss).backward()  # Scale loss before backpropagation

        if (i + 1) % accumulation_steps == 0:
            scaler.step(optimizer)  # Update weights
            scaler.update()  # Update scaler
            optimizer.zero_grad()

        # ... (rest of your code)

!pip install timm

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm

def train_model():
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
    transform = transforms.Compose([
        transforms.Resize((299, 299)),  # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø­Ø¬Ù… Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Xception
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
    ])

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø¹ ØªÙ‚Ù„ÙŠÙ„ batch size
    train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # ØªÙ‚Ù„ÙŠÙ„ batch size

    # ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Xception Ø§Ù„Ù…Ø¹Ø¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§
    model = timm.create_model('xception', pretrained=True)

    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
    in_features = model.get_classifier().in_features
    model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

    # Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø£Ùˆ CPU)
    model.to(device)

    # ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
    optimizer = optim.Adam(model.parameters(), lr=1e-5)

    # ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
    loss_fn = nn.CrossEntropyLoss()

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    epochs = 10
    for epoch in range(epochs):
        running_loss = 0.0
        correct_preds = 0
        total_preds = 0

        model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£ÙˆØ³Ù…Ø© ÙˆØªØµØ­ÙŠØ­Ù‡Ø§ Ø¥Ù† Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            labels = labels.clamp(0, 1)  # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† labels ØªÙ‚Ø¹ Ø¨ÙŠÙ† 0 Ùˆ 1

            try:
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
                outputs = model(images)

                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
                loss = loss_fn(outputs, labels)
                loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

                optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
                _, predicted = torch.max(outputs, 1)
                correct_preds += (predicted == labels).sum().item()
                total_preds += labels.size(0)

                running_loss += loss.item()

            except RuntimeError as e:
                torch.cuda.empty_cache()
                print(f"Skipped batch due to insufficient memory or mismatch: {e}")

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
        epoch_loss = running_loss / len(train_loader)
        epoch_accuracy = correct_preds / total_preds

        print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

train_model()

import matplotlib.pyplot as plt

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
losses = [0.2594, 0.1397, 0.1033, 0.0764, 0.0593, 0.0462, 0.0370, 0.0250, 0.0196, 0.0129]
accuracies = [0.9575, 0.9586, 0.9586, 0.9586, 0.9604, 0.9704, 0.9852, 0.9956, 0.9985, 0.9985]

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
plt.figure(figsize=(12, 5))

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
plt.subplot(1, 2, 1)
plt.plot(epochs, losses, marker='o', color='red', label='Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
plt.subplot(1, 2, 2)
plt.plot(epochs, accuracies, marker='o', color='green', label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

# Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙƒØµÙˆØ±Ø©
plt.tight_layout()
plt.savefig('training_results_xception.png')
plt.show()

import pandas as pd
from google.colab import files

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
epochs = list(range(1, 11))
losses = [0.2594, 0.1397, 0.1033, 0.0764, 0.0593, 0.0462, 0.0370, 0.0250, 0.0196, 0.0129]
accuracies = [0.9575, 0.9586, 0.9586, 0.9586, 0.9604, 0.9704, 0.9852, 0.9956, 0.9985, 0.9985]

# Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
results_df = pd.DataFrame({
    'Epoch': epochs,
    'Loss': losses,
    'Accuracy': accuracies
})

# Ø­ÙØ¸ DataFrame ÙÙŠ Ù…Ù„Ù Excel
results_df.to_excel('training_results_xception.xlsx', index=False)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù ÙƒÙ„ÙŠØ¨ ÙÙŠ Colab
files.download('training_results_xception.xlsx')

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ CUDA
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù†Ù…ÙˆØ°Ø¬ InceptionV3
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ InceptionV3 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.inception_v3(weights='DEFAULT')
model.aux_logits = False  # ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù€ aux_logits Ù„Ø£Ù†Ù†Ø§ Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# Ù…Ø­Ø§ÙˆÙ„Ø© Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    model.to(device)
except RuntimeError as e:
    print(f"Error moving model to device: {e}")

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø£ÙˆØ³Ù…Ø© ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø±Ø¬ÙˆØ©
        labels = labels.clamp(0, 1)  # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø£ÙˆØ³Ù…Ø© ØªÙ‚Ø¹ Ø¨ÙŠÙ† 0 Ùˆ 1

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        try:
            outputs = model(images)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
            loss = loss_fn(outputs, labels)
            loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

            optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            _, predicted = torch.max(outputs, 1)
            correct_preds += (predicted == labels).sum().item()
            total_preds += labels.size(0)

            running_loss += loss.item()

        except RuntimeError as e:
            torch.cuda.empty_cache()
            print(f"Runtime error: {e}")

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ù…Ø¹Ø±ÙØ© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙˆÙ…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø³Ù…
if torch.cuda.is_available():
    print(f"GPU device count: {torch.cuda.device_count()}")
    print(f"GPU device name: {torch.cuda.get_device_name(0)}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù†Ù…ÙˆØ°Ø¬ InceptionV3
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ InceptionV3 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.inception_v3(weights='DEFAULT')
model.aux_logits = False

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# Ù…Ø­Ø§ÙˆÙ„Ø© Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø²
model.to(device)

# Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ
...

pip install numpy --upgrade

pip install numpy

!pip install numpy

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import numpy as np

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù†Ù…ÙˆØ°Ø¬ InceptionV3
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ØªØ·Ø¨ÙŠØ¹ Ù…Ø«Ù„ ImageNet
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_dataset = ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ InceptionV3 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
model.aux_logits = False  # ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù€ aux_logits Ù„Ø£Ù†Ù†Ø§ Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø²
model.to(device)

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()  # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # ØªØ¶Ù…ÙŠÙ† ÙØ­Øµ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø£ÙˆØ³Ù…Ø© Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        if torch.any(labels >= 2):
            print(f"Encountered label out of bounds: {labels}")
            continue  # ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¯ÙØ¹Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙˆØ³Ù…Ø© ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚Ø©

        optimizer.zero_grad()  # ØªÙØ±ÙŠØº Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(outputs, labels)
        loss.backward()  # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª

        optimizer.step()  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ÙƒÙ„ epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import numpy as np

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† GPU Ù…ØªØ§Ø­Ù‹Ø§
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_dataset = ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)

# Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£ÙˆØ³Ù…Ø© Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù„ØªØ³Ù‡ÙŠÙ„ ØªØµØ­ÙŠØ­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
unique_labels = set()
for _, label in train_dataset:
    unique_labels.add(label)
print("Unique labels found:", unique_labels)

# Ø¥Ø¹Ø¯Ø§Ø¯ DataLoader Ù…Ø¹ ÙÙ„ØªØ±Ø© Ø§Ù„Ø£ÙˆØ³Ù…Ø© ØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø©
filtered_train_dataset = [(image, label) for image, label in train_dataset if label < 2]
train_loader = DataLoader(filtered_train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ InceptionV3 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
model.aux_logits = False

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 2)  # 2 ÙØ¦Ø§Øª: Ø³Ù„ÙŠÙ… Ùˆ Ù…Ø±ÙŠØ¶

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø²
model.to(device)

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ logits
        outputs = model(images)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        loss = loss_fn(outputs, labels)
        loss.backward()

        optimizer.step()

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_dataset = ImageFolder(root='/content/drive/MyDrive/extracted_data', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ InceptionV3
model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
model.aux_logits = False

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, 3)  # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø«Ù„Ø§Ø« ÙØ¦Ø§Øª

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø²
model.to(device)

# ØªØ¹Ø±ÙŠÙ optimizer Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Adam
optimizer = optim.Adam(model.parameters(), lr=1e-5)

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
epochs = 10
for epoch in range(epochs):
    running_loss = 0.0
    correct_preds = 0
    total_preds = 0

    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(images)

        loss = loss_fn(outputs, labels)
        loss.backward()

        optimizer.step()

        _, predicted = torch.max(outputs, 1)
        correct_preds += (predicted == labels).sum().item()
        total_preds += labels.size(0)

        running_loss += loss.item()

    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = correct_preds / total_preds

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
epochs_observed = np.array([1, 2, 3, 4, 5])
loss_observed = np.array([0.8454, 0.5080, 0.3562, 0.2890, 0.2235])
accuracy_observed = np.array([0.7056, 0.8746, 0.8761, 0.8913, 0.9368])

# Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ø§Ù„Ø¨Ø³ÙŠØ·
def predict_future_epochs(epochs_observed, values_observed, epochs_to_predict):
    model = LinearRegression()
    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model.fit(epochs_observed.reshape(-1, 1), values_observed)
    # ØªÙˆÙ‚Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ù„Ù„ÙØªØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©
    future_epochs = np.arange(epochs_observed[-1] + 1, epochs_observed[-1] + 1 + epochs_to_predict)
    predictions = model.predict(future_epochs.reshape(-1, 1))
    return future_epochs, predictions

# ØªÙˆÙ‚Ø¹ Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© Ù„Ù„ÙØªØ±Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ø­ØªÙ‰ Ø§Ù„ÙØªØ±Ø© 10
future_epochs_loss, predicted_loss = predict_future_epochs(epochs_observed, loss_observed, 5)
future_epochs_accuracy, predicted_accuracy = predict_future_epochs(epochs_observed, accuracy_observed, 5)

# Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù„Ù„Ø¹Ø±Ø¶
all_epochs = np.concatenate([epochs_observed, future_epochs_loss])
all_loss = np.concatenate([loss_observed, predicted_loss])
all_accuracy = np.concatenate([accuracy_observed, predicted_accuracy])

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
plt.figure(figsize=(12, 5))

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
plt.subplot(1, 2, 1)
plt.plot(all_epochs, all_loss, marker='o', color='red', label='Loss')
plt.scatter(future_epochs_loss, predicted_loss, marker='x', color='black', label='Predicted Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.grid(True)
plt.legend()

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
plt.subplot(1, 2, 2)
plt.plot(all_epochs, all_accuracy, marker='o', color='green', label='Accuracy')
plt.scatter(future_epochs_accuracy, predicted_accuracy, marker='x', color='black', label='Predicted Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()

# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù„ÙƒÙ„ ÙØªØ±Ø© Ù…ØªØ¨Ù‚ÙŠØ©
for epoch, loss, acc in zip(future_epochs_loss, predicted_loss, predicted_accuracy):
    print(f"Epoch {epoch}, Predicted Loss: {loss:.4f}, Predicted Accuracy: {acc:.4f}")

# 1. Ø±Ø¨Ø· Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
import zipfile
import random
import os
from PIL import Image
import io
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader

# 3. Ù…Ø³Ø§Ø± Ù…Ù„Ù zip
zip_path = '/content/drive/MyDrive/----_2.v1i.multiclass.zip'

# 4. ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª (ØªØ£ÙƒØ¯ Ù…Ù† Ù†ÙØ³ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 5. ØªØ¹Ø±ÙŠÙ ÙƒÙ„Ø§Ø³ Ù…Ø®ØµØµ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù…Ù† zip
class ZipDataset(Dataset):
    def __init__(self, zip_path, selected_files, transform=None, class_to_idx=None):
        self.zip_path = zip_path
        self.selected_files = selected_files
        self.transform = transform
        self.class_to_idx = class_to_idx  # ØªØ­ÙˆÙŠÙ„ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ø¥Ù„Ù‰ Ø±Ù‚Ù…

    def __len__(self):
        return len(self.selected_files)

    def __getitem__(self, idx):
        with zipfile.ZipFile(self.zip_path, 'r') as archive:
            file = self.selected_files[idx]
            with archive.open(file) as image_file:
                img = Image.open(image_file).convert('RGB')
                if self.transform:
                    img = self.transform(img)
                label_name = file.split('/')[0]
                label = self.class_to_idx[label_name]
        return img, label

# 6. Ù‚Ø±Ø§Ø¡Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ zip
with zipfile.ZipFile(zip_path, 'r') as archive:
    all_files = [f for f in archive.namelist() if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

print(f"Ø¹Ø¯Ø¯ ÙƒÙ„ Ø§Ù„ØµÙˆØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„Ù: {len(all_files)}")

# 7. Ù…Ø¹Ø±ÙØ© Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª (Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª)
classes = sorted(list({f.split('/')[0] for f in all_files}))
class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}

print(f"Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª: {class_to_idx}")

# 8. Ø§Ø®ØªÙŠØ§Ø± 300 ØµÙˆØ±Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§
selected_files = random.sample(all_files, 300)

# 9. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ø§ØªØ§ Ù„ÙˆØ¯Ø±
test_dataset = ZipDataset(zip_path

# Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª .pth ÙÙŠ Ø¯Ø±Ø§ÙŠÙ
!find /content/drive/MyDrive/ -name "*.pth"

# Ø±Ø¨Ø· Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
import zipfile
import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

# Ù†Ø³Ø® Ù…Ù„Ù zip
!cp "/content/drive/MyDrive/----_2.v1i.multiclass.zip" /content/

# ÙÙƒ Ø§Ù„Ø¶ØºØ·
zip_path = '/content/----_2.v1i.multiclass.zip'
extract_path = '/content/dataset'
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… ØªÙ… ÙÙƒ Ø§Ù„Ø¶ØºØ·!")

# ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ø§ØªØ§
full_dataset = datasets.ImageFolder(root=extract_path, transform=transform)

# ØªÙ‚Ø³ÙŠÙ… Train Ùˆ Validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# Ø¯Ø§ØªØ§ Ù„ÙˆØ¯Ø±
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# Ø·Ø¨Ø§Ø¹Ø© ØªØ£ÙƒÙŠØ¯
print(f"âœ… ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(train_dataset)}, ØµÙˆØ± Ø§Ù„ØªØ­Ù‚Ù‚: {len(val_dataset)}")

import matplotlib.pyplot as plt

# Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ÙˆØ®Ø³Ø§Ø±Ø© Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
epochs = range(1, 11)  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ØµÙˆØ± (Ø§Ù„Ø£Ù…Ø«Ù„Ø©)
train_accuracy = [0.84, 0.87, 0.90, 0.92, 0.94, 0.96, 0.98, 0.99, 1.00, 1.00]
val_accuracy = [0.83, 0.86, 0.89, 0.91, 0.93, 0.95, 0.97, 0.98, 1.00, 1.00]
train_loss = [0.50, 0.40, 0.35, 0.30, 0.25, 0.20, 0.15, 0.10, 0.05, 0.01]
val_loss = [0.52, 0.42, 0.37, 0.32, 0.27, 0.22, 0.17, 0.12, 0.06, 0.02]

# Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

# Ø±Ø³Ù… Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
ax1.plot(epochs, train_accuracy, label='Training Accuracy', color='blue')
ax1.plot(epochs, val_accuracy, label='Validation Accuracy', color='orange')
ax1.set_title('Training Accuracy Over Epochs')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy')
ax1.legend()

# Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø©
ax2.plot(epochs, train_loss, label='Training Loss', color='red')
ax2.plot(epochs, val_loss, label='Validation Loss', color='green')
ax2.set_title('Training Loss Over Epochs')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss')
ax2.legend()

plt.tight_layout()
plt.show()

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
train_data_dir = 'path_to_train_data'  # Ø§Ø³ØªØ¨Ø¯Ù„ Ù‡Ø°Ø§ Ø¨Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
valid_data_dir = 'path_to_valid_data'  # Ø§Ø³ØªØ¨Ø¯Ù„ Ù‡Ø°Ø§ Ø¨Ù…Ø³Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'  # Ø£Ùˆ 'binary' Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø«Ù†Ø§Ø¦ÙŠØ©
)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'  # Ø£Ùˆ 'binary' Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø«Ù†Ø§Ø¦ÙŠØ©
)

# ØªØ­Ù…ÙŠÙ„ EfficientNetB0 Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¹Ù„ÙˆÙŠØ©
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Ø¥Ø¶Ø§ÙØ© Ø·Ø¨Ù‚Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(len(train_generator.class_indices), activation='softmax')(x)  # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ

# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
model = Model(inputs=base_model.input, outputs=x)

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.summary()

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=10,
    verbose=1
)